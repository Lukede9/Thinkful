{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data cleaning / processing / language parsing\n",
    "- Create features using two different NLP methods: For example, BoW vs tf-idf.\n",
    "- Use the features to fit supervised learning models for each feature set to predict the category outcomes.\n",
    "- Assess your models using cross-validation and determine whether one model performed better.\n",
    "- Pick one of the models and try to increase accuracy by at least 5 percentage points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to shrink things down for my baby computer. In this case, I want to keep all the articles that have at least 10 of that genre. And I want to just take the first 1000 words of the article rather than the whole thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import brown, stopwords\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/lukeelliott/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/lukeelliott/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This imports the txt file and names the column 'info'\n",
    "longform = pd.read_csv(\"cats.txt\", sep='\\n', header=None)\n",
    "longform.columns = ['info']\n",
    "\n",
    "# Grabs first 4 characters of a string\n",
    "def get_keys(txt):\n",
    "    return txt[:4]\n",
    "\n",
    "# Grabs all but first 4 characters of a string\n",
    "def drop_column_names(txt):\n",
    "    return txt[4:]\n",
    "\n",
    "# Function takes in a dirty, longform DataFrame and pops it back out cleaned\n",
    "# and split into two columns\n",
    "def longform_cleaning(df):\n",
    "    df['keys'] = df['info'].apply(lambda x: get_keys(x))\n",
    "\n",
    "    df['info'] = df['info'].apply(lambda x: drop_column_names(x))\n",
    "\n",
    "    df['info'] = df['info'].apply(lambda x: x.strip())\n",
    "    \n",
    "    return df\n",
    "\n",
    "labels_df = longform_cleaning(longform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "list_of_dfs = []\n",
    "for i in brown.categories():\n",
    "    d[str(i)] = labels_df[labels_df['info'] == i]\n",
    "    if len(d[str(i)]) > 19:\n",
    "        list_of_dfs.append(d[str(i)][0:10])\n",
    "        \n",
    "labels_df = pd.concat(list_of_dfs).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = labels_df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts all the article words and punctuation into dataframe column\n",
    "article_col = []\n",
    "for article in labels_df['keys']:\n",
    "    article_col.append(text_cleaner(' '.join(brown.words(fileids=[article]))))\n",
    "\n",
    "labels_df['article_words'] = article_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df['1000_tokens'] = labels_df['article_words'].apply(lambda x: word_tokenize(x))\n",
    "labels_df['first_1000_words'] = labels_df['1000_tokens'].apply(lambda x: x[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts all the article words and punctuation into dataframe column\n",
    "article_col1000 = []\n",
    "for article in labels_df['first_1000_words']:\n",
    "    article_col1000.append(text_cleaner(' '.join(article)))\n",
    "\n",
    "labels_df['article_words1000'] = article_col1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "      <th>keys</th>\n",
       "      <th>article_words</th>\n",
       "      <th>1000_tokens</th>\n",
       "      <th>first_1000_words</th>\n",
       "      <th>article_words1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adventure</td>\n",
       "      <td>cn01</td>\n",
       "      <td>Dan Morgan told himself he would forget Ann Tu...</td>\n",
       "      <td>[Dan, Morgan, told, himself, he, would, forget...</td>\n",
       "      <td>[Dan, Morgan, told, himself, he, would, forget...</td>\n",
       "      <td>Dan Morgan told himself he would forget Ann Tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adventure</td>\n",
       "      <td>cn02</td>\n",
       "      <td>Gavin paused wearily . `` You can't stay here ...</td>\n",
       "      <td>[Gavin, paused, wearily, ., ``, You, ca, n't, ...</td>\n",
       "      <td>[Gavin, paused, wearily, ., ``, You, ca, n't, ...</td>\n",
       "      <td>Gavin paused wearily . `` You ca n't stay here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adventure</td>\n",
       "      <td>cn03</td>\n",
       "      <td>The sentry was not dead . He was , in fact , s...</td>\n",
       "      <td>[The, sentry, was, not, dead, ., He, was, ,, i...</td>\n",
       "      <td>[The, sentry, was, not, dead, ., He, was, ,, i...</td>\n",
       "      <td>The sentry was not dead . He was , in fact , s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adventure</td>\n",
       "      <td>cn04</td>\n",
       "      <td>`` So it wasn't the earthquake that made him r...</td>\n",
       "      <td>[``, So, it, was, n't, the, earthquake, that, ...</td>\n",
       "      <td>[``, So, it, was, n't, the, earthquake, that, ...</td>\n",
       "      <td>`` So it was n't the earthquake that made him ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adventure</td>\n",
       "      <td>cn05</td>\n",
       "      <td>She was carrying a quirt , and she started to ...</td>\n",
       "      <td>[She, was, carrying, a, quirt, ,, and, she, st...</td>\n",
       "      <td>[She, was, carrying, a, quirt, ,, and, she, st...</td>\n",
       "      <td>She was carrying a quirt , and she started to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        info  keys                                      article_words  \\\n",
       "0  adventure  cn01  Dan Morgan told himself he would forget Ann Tu...   \n",
       "1  adventure  cn02  Gavin paused wearily . `` You can't stay here ...   \n",
       "2  adventure  cn03  The sentry was not dead . He was , in fact , s...   \n",
       "3  adventure  cn04  `` So it wasn't the earthquake that made him r...   \n",
       "4  adventure  cn05  She was carrying a quirt , and she started to ...   \n",
       "\n",
       "                                         1000_tokens  \\\n",
       "0  [Dan, Morgan, told, himself, he, would, forget...   \n",
       "1  [Gavin, paused, wearily, ., ``, You, ca, n't, ...   \n",
       "2  [The, sentry, was, not, dead, ., He, was, ,, i...   \n",
       "3  [``, So, it, was, n't, the, earthquake, that, ...   \n",
       "4  [She, was, carrying, a, quirt, ,, and, she, st...   \n",
       "\n",
       "                                    first_1000_words  \\\n",
       "0  [Dan, Morgan, told, himself, he, would, forget...   \n",
       "1  [Gavin, paused, wearily, ., ``, You, ca, n't, ...   \n",
       "2  [The, sentry, was, not, dead, ., He, was, ,, i...   \n",
       "3  [``, So, it, was, n't, the, earthquake, that, ...   \n",
       "4  [She, was, carrying, a, quirt, ,, and, she, st...   \n",
       "\n",
       "                                   article_words1000  \n",
       "0  Dan Morgan told himself he would forget Ann Tu...  \n",
       "1  Gavin paused wearily . `` You ca n't stay here...  \n",
       "2  The sentry was not dead . He was , in fact , s...  \n",
       "3  `` So it was n't the earthquake that made him ...  \n",
       "4  She was carrying a quirt , and she started to ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "spacy_articles = []\n",
    "for article in labels_df['article_words1000']:\n",
    "    spacy_articles.append(nlp(article))\n",
    "    \n",
    "labels_df['spacy_articles'] = spacy_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "belles_lettres    10\n",
       "lore              10\n",
       "mystery           10\n",
       "fiction           10\n",
       "government        10\n",
       "romance           10\n",
       "hobbies           10\n",
       "learned           10\n",
       "editorial         10\n",
       "news              10\n",
       "adventure         10\n",
       "Name: info, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df['info'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "      <th>keys</th>\n",
       "      <th>article_words</th>\n",
       "      <th>1000_tokens</th>\n",
       "      <th>first_1000_words</th>\n",
       "      <th>article_words1000</th>\n",
       "      <th>spacy_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adventure</td>\n",
       "      <td>cn01</td>\n",
       "      <td>Dan Morgan told himself he would forget Ann Tu...</td>\n",
       "      <td>[Dan, Morgan, told, himself, he, would, forget...</td>\n",
       "      <td>[Dan, Morgan, told, himself, he, would, forget...</td>\n",
       "      <td>Dan Morgan told himself he would forget Ann Tu...</td>\n",
       "      <td>(Dan, Morgan, told, himself, he, would, forget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adventure</td>\n",
       "      <td>cn02</td>\n",
       "      <td>Gavin paused wearily . `` You can't stay here ...</td>\n",
       "      <td>[Gavin, paused, wearily, ., ``, You, ca, n't, ...</td>\n",
       "      <td>[Gavin, paused, wearily, ., ``, You, ca, n't, ...</td>\n",
       "      <td>Gavin paused wearily . `` You ca n't stay here...</td>\n",
       "      <td>(Gavin, paused, wearily, ., ``, You, ca, n't, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adventure</td>\n",
       "      <td>cn03</td>\n",
       "      <td>The sentry was not dead . He was , in fact , s...</td>\n",
       "      <td>[The, sentry, was, not, dead, ., He, was, ,, i...</td>\n",
       "      <td>[The, sentry, was, not, dead, ., He, was, ,, i...</td>\n",
       "      <td>The sentry was not dead . He was , in fact , s...</td>\n",
       "      <td>(The, sentry, was, not, dead, ., He, was, ,, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adventure</td>\n",
       "      <td>cn04</td>\n",
       "      <td>`` So it wasn't the earthquake that made him r...</td>\n",
       "      <td>[``, So, it, was, n't, the, earthquake, that, ...</td>\n",
       "      <td>[``, So, it, was, n't, the, earthquake, that, ...</td>\n",
       "      <td>`` So it was n't the earthquake that made him ...</td>\n",
       "      <td>(``, So, it, was, n't, the, earthquake, that, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adventure</td>\n",
       "      <td>cn05</td>\n",
       "      <td>She was carrying a quirt , and she started to ...</td>\n",
       "      <td>[She, was, carrying, a, quirt, ,, and, she, st...</td>\n",
       "      <td>[She, was, carrying, a, quirt, ,, and, she, st...</td>\n",
       "      <td>She was carrying a quirt , and she started to ...</td>\n",
       "      <td>(She, was, carrying, a, quirt, ,, and, she, st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        info  keys                                      article_words  \\\n",
       "0  adventure  cn01  Dan Morgan told himself he would forget Ann Tu...   \n",
       "1  adventure  cn02  Gavin paused wearily . `` You can't stay here ...   \n",
       "2  adventure  cn03  The sentry was not dead . He was , in fact , s...   \n",
       "3  adventure  cn04  `` So it wasn't the earthquake that made him r...   \n",
       "4  adventure  cn05  She was carrying a quirt , and she started to ...   \n",
       "\n",
       "                                         1000_tokens  \\\n",
       "0  [Dan, Morgan, told, himself, he, would, forget...   \n",
       "1  [Gavin, paused, wearily, ., ``, You, ca, n't, ...   \n",
       "2  [The, sentry, was, not, dead, ., He, was, ,, i...   \n",
       "3  [``, So, it, was, n't, the, earthquake, that, ...   \n",
       "4  [She, was, carrying, a, quirt, ,, and, she, st...   \n",
       "\n",
       "                                    first_1000_words  \\\n",
       "0  [Dan, Morgan, told, himself, he, would, forget...   \n",
       "1  [Gavin, paused, wearily, ., ``, You, ca, n't, ...   \n",
       "2  [The, sentry, was, not, dead, ., He, was, ,, i...   \n",
       "3  [``, So, it, was, n't, the, earthquake, that, ...   \n",
       "4  [She, was, carrying, a, quirt, ,, and, she, st...   \n",
       "\n",
       "                                   article_words1000  \\\n",
       "0  Dan Morgan told himself he would forget Ann Tu...   \n",
       "1  Gavin paused wearily . `` You ca n't stay here...   \n",
       "2  The sentry was not dead . He was , in fact , s...   \n",
       "3  `` So it was n't the earthquake that made him ...   \n",
       "4  She was carrying a quirt , and she started to ...   \n",
       "\n",
       "                                      spacy_articles  \n",
       "0  (Dan, Morgan, told, himself, he, would, forget...  \n",
       "1  (Gavin, paused, wearily, ., ``, You, ca, n't, ...  \n",
       "2  (The, sentry, was, not, dead, ., He, was, ,, i...  \n",
       "3  (``, So, it, was, n't, the, earthquake, that, ...  \n",
       "4  (She, was, carrying, a, quirt, ,, and, she, st...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spacy_articles has the spacy breakdowns\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: reduce to lemmas, remove stopwords and punctuation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to run bag of words and create a common words list but only include the words that appear more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    common_words = []\n",
    "    for item in Counter(allwords).most_common(2000):\n",
    "        if item[1] > 1:\n",
    "            print(item[0])\n",
    "            common_words.append(item[0])\n",
    "    return common_words\n",
    "\n",
    "def bow_features(text, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text'] = text['spacy_articles']\n",
    "    df['genre'] = text['info']\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 10 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-PRON-\n",
      "ann\n",
      "n't\n",
      "night\n",
      "sleep\n",
      "the\n",
      "work\n",
      "find\n",
      "day\n",
      "little\n",
      "``\n",
      "-PRON-\n",
      "gavin\n",
      "man\n",
      "n't\n",
      "say\n",
      "chair\n",
      "rock\n",
      "pain\n",
      "clayton\n",
      "-PRON-\n",
      "``\n",
      "the\n",
      "belt\n",
      "mike\n",
      "dean\n",
      "fiske\n",
      "say\n",
      "will\n",
      "``\n",
      "-PRON-\n",
      "n't\n",
      "jason\n",
      "the\n",
      "large\n",
      "war\n",
      "party\n",
      "say\n",
      "shout\n",
      "fort\n",
      "cook\n",
      "``\n",
      "-PRON-\n",
      "fire\n",
      "say\n",
      "be\n",
      "let\n",
      "burn\n",
      "big\n",
      "and\n",
      "appreciate\n",
      "m\n",
      "take\n",
      "-PRON-\n",
      "hall\n",
      "the\n",
      "``\n",
      "'s\n",
      "-PRON-\n",
      "the\n",
      "rankin\n",
      "barton\n",
      "hard\n",
      "head\n",
      "swing\n",
      "man\n",
      "let\n",
      "``\n",
      "pamela\n",
      "mother\n",
      "melissa\n",
      "auntie\n",
      "grace\n",
      "station\n",
      "wagon\n",
      "-PRON-\n",
      "simple\n",
      "-PRON-\n",
      "``\n",
      "lord\n",
      "listen\n",
      "want\n",
      "ve\n",
      "get\n",
      "n't\n",
      "but\n",
      "be\n",
      "go\n",
      "the\n",
      "'s\n",
      "herd\n",
      "-PRON-\n",
      "outfit\n",
      "know\n",
      "night\n",
      "hand\n",
      "coffee\n",
      "fire\n",
      "-PRON-\n",
      "liberal\n",
      "the\n",
      "north\n",
      "northern\n",
      "welfare\n",
      "discrimination\n",
      "social\n",
      "bourbons\n",
      "south\n",
      "``\n",
      "state\n",
      "western\n",
      "world\n",
      "order\n",
      "nation\n",
      "position\n",
      "law\n",
      "power\n",
      "``\n",
      "man\n",
      "war\n",
      "be\n",
      "increase\n",
      "-PRON-\n",
      "ask\n",
      "question\n",
      "submarine\n",
      "launch\n",
      "missile\n",
      "room\n",
      "button\n",
      "-PRON-\n",
      "go\n",
      "squall\n",
      "game\n",
      "see\n",
      "rain\n",
      "cloud\n",
      "degree\n",
      "the\n",
      "``\n",
      "isfahan\n",
      "time\n",
      "century\n",
      "great\n",
      "the\n",
      "tile\n",
      "city\n",
      "traveler\n",
      "desert\n",
      "in\n",
      "``\n",
      "-PRON-\n",
      "maestro\n",
      "the\n",
      "explain\n",
      "life\n",
      "pittsburgh\n",
      "orchestra\n",
      "steinberg\n",
      "london\n",
      "conduct\n",
      "concert\n",
      "``\n",
      "nation\n",
      "founding\n",
      "fathers\n",
      "america\n",
      "test\n",
      "determine\n",
      "-PRON-\n",
      "national\n",
      "john\n",
      "jefferson\n",
      "madison\n",
      "tobacco\n",
      "road\n",
      "southern\n",
      "writer\n",
      "live\n",
      "today\n",
      "urbanization\n",
      "south\n",
      "``\n",
      "critic\n",
      "lead\n",
      "mr.\n",
      "dancer\n",
      "'s\n",
      "theatre\n",
      "self\n",
      "line\n",
      "color\n",
      "-PRON-\n",
      "costume\n",
      "nikolais\n",
      "the\n",
      "compromise\n",
      "sovereignty\n",
      "concept\n",
      "people\n",
      "democratic\n",
      "federal\n",
      "union\n",
      "sovereign\n",
      "crisis\n",
      "assembly\n",
      "good\n",
      "session\n",
      "the\n",
      "general\n",
      "school\n",
      "decision\n",
      "executive\n",
      "way\n",
      "year\n",
      "bill\n",
      "berlin\n",
      "``\n",
      "city\n",
      "soviet\n",
      "the\n",
      "communists\n",
      "acquiesce\n",
      "east\n",
      "germany\n",
      "zone\n",
      "occupation\n",
      "mr.\n",
      "good\n",
      "man\n",
      "sam\n",
      "rayburn\n",
      "-PRON-\n",
      "democrat\n",
      "speaker\n",
      "house\n",
      "new\n",
      "deal\n",
      "politician\n",
      "-PRON-\n",
      "peace\n",
      "hammarskjold\n",
      "crash\n",
      "the\n",
      "africa\n",
      "'s\n",
      "death\n",
      "plane\n",
      "united\n",
      "nations\n",
      "come\n",
      "mr.\n",
      "controversial\n",
      "dominican\n",
      "trujillo\n",
      "u.s.\n",
      "free\n",
      "government\n",
      "balaguer\n",
      "ciudad\n",
      "opposition\n",
      "leader\n",
      "american\n",
      "``\n",
      "st.\n",
      "louis\n",
      "'s\n",
      "industry\n",
      "missouri\n",
      "area\n",
      "the\n",
      "metropolitan\n",
      "illinois\n",
      "slow\n",
      "region\n",
      "regional\n",
      "purchasing\n",
      "power\n",
      "growth\n",
      "new\n",
      "``\n",
      "the\n",
      "u.n.\n",
      "shall\n",
      "'s\n",
      "grave\n",
      "crisis\n",
      "stevenson\n",
      "dag\n",
      "hammarskjold\n",
      "secretary\n",
      "general\n",
      "charter\n",
      "organization\n",
      "staff\n",
      "-PRON-\n",
      "year\n",
      "say\n",
      "close\n",
      "grow\n",
      "beef\n",
      "ready\n",
      "this\n",
      "happen\n",
      "county\n",
      "georgia\n",
      "podger\n",
      "the\n",
      "mr.\n",
      "night\n",
      "fringe\n",
      "summer\n",
      "pod\n",
      "come\n",
      "porch\n",
      "prize\n",
      "push\n",
      "``\n",
      "-PRON-\n",
      "say\n",
      "open\n",
      "writer\n",
      "richards\n",
      "manager\n",
      "year\n",
      "now\n",
      "vice\n",
      "versa\n",
      "this\n",
      "be\n",
      "lot\n",
      "increase\n",
      "population\n",
      "rookie\n",
      "-PRON-\n",
      "scotty\n",
      "school\n",
      "parent\n",
      "hospital\n",
      "mr.\n",
      "mckinley\n",
      "term\n",
      "choose\n",
      "``\n",
      "papa\n",
      "san\n",
      "``\n",
      "'s\n",
      "sit\n",
      "like\n",
      "objective\n",
      "valley\n",
      "await\n",
      "slope\n",
      "stretch\n",
      "barbed\n",
      "wire\n",
      "child\n",
      "small\n",
      "the\n",
      "-PRON-\n",
      "little\n",
      "bar\n",
      "al\n",
      "hang\n",
      "nude\n",
      "student\n",
      "drink\n",
      "``\n",
      "``\n",
      "city\n",
      "river\n",
      "the\n",
      "look\n",
      "say\n",
      "but\n",
      "birmingham\n",
      "near\n",
      "region\n",
      "-PRON-\n",
      "the\n",
      "payne\n",
      "herold\n",
      "seward\n",
      "sick\n",
      "'s\n",
      "bell\n",
      "katie\n",
      "with\n",
      "rear\n",
      "stevie\n",
      "stranger\n",
      "the\n",
      "man\n",
      "time\n",
      "-PRON-\n",
      "bring\n",
      "-PRON-\n",
      "nigger\n",
      "sweet\n",
      "pussy\n",
      "think\n",
      "if\n",
      "write\n",
      "be\n",
      "fucken\n",
      "oh\n",
      "come\n",
      "juicy\n",
      "love\n",
      "the\n",
      "snow\n",
      "fix\n",
      "n't\n",
      "``\n",
      "voltaire\n",
      "man\n",
      "-PRON-\n",
      "go\n",
      "learn\n",
      "bandit\n",
      "chief\n",
      "but\n",
      "say\n",
      "the\n",
      "study\n",
      "-PRON-\n",
      "come\n",
      "be\n",
      "hear\n",
      "rider\n",
      "horse\n",
      "``\n",
      "man\n",
      "see\n",
      "the\n",
      "longer\n",
      "bordel\n",
      "'s\n",
      "morning\n",
      "woman\n",
      "god\n",
      "-PRON-\n",
      "business\n",
      "small\n",
      "office\n",
      "u.s.\n",
      "commerce\n",
      "information\n",
      "the\n",
      "economics\n",
      "department\n",
      "provide\n",
      "measure\n",
      "national\n",
      "economy\n",
      "current\n",
      "economic\n",
      "government\n",
      "contact\n",
      "washington\n",
      "25\n",
      "d.c.\n",
      "available\n",
      "weekly\n",
      "supplement\n",
      "technical\n",
      "programing\n",
      "development\n",
      "project\n",
      "program\n",
      "country\n",
      "only\n",
      "goal\n",
      "assistance\n",
      "-PRON-\n",
      "``\n",
      "mr.\n",
      "young\n",
      "people\n",
      "year\n",
      "see\n",
      "free\n",
      "speaker\n",
      "president\n",
      "ask\n",
      "run\n",
      "extend\n",
      "state\n",
      "vehicle\n",
      "the\n",
      "purchase\n",
      "own\n",
      "use\n",
      "policy\n",
      "automobile\n",
      "practice\n",
      "existence\n",
      "maintenance\n",
      "unit\n",
      "motor\n",
      "pool\n",
      "management\n",
      "tax\n",
      "state\n",
      "property\n",
      "time\n",
      "year\n",
      "local\n",
      "government\n",
      "city\n",
      "town\n",
      "this\n",
      "service\n",
      "financial\n",
      "assistance\n",
      "new\n",
      "rhode\n",
      "island\n",
      "industry\n",
      "'s\n",
      "1960\n",
      "company\n",
      "expansion\n",
      "investment\n",
      "industrial\n",
      "development\n",
      "plant\n",
      "firm\n",
      "r.\n",
      "corporation\n",
      "special\n",
      "district\n",
      "government\n",
      "state\n",
      "rhode\n",
      "island\n",
      "authority\n",
      "fiscal\n",
      "-PRON-\n",
      "report\n",
      "unit\n",
      "seven\n",
      "levy\n",
      "tax\n",
      "property\n",
      "sue\n",
      "rhode\n",
      "island\n",
      "independence\n",
      "commemorate\n",
      "heritage\n",
      "week\n",
      "john\n",
      "a.\n",
      "notte\n",
      "jr.\n",
      "governor\n",
      "the\n",
      "``\n",
      "-PRON-\n",
      "water\n",
      "united\n",
      "states\n",
      "congress\n",
      "act\n",
      "1952\n",
      "amend\n",
      "saline\n",
      "term\n",
      "include\n",
      "pathology\n",
      "forensic\n",
      "during\n",
      "fiscal\n",
      "year\n",
      "course\n",
      "conduct\n",
      "application\n",
      "histochemistry\n",
      "diseases\n",
      "laboratory\n",
      "animals\n",
      "1960\n",
      "staff\n",
      "education\n",
      "1959\n",
      "ophthalmic\n",
      "oral\n",
      "regions\n",
      "sciences\n",
      "symposium\n",
      "orthopedic\n",
      "``\n",
      "parent\n",
      "henri\n",
      "bodybuilder\n",
      "n't\n",
      "taunt\n",
      "schoolmate\n",
      "mr.\n",
      "be\n",
      "happy\n",
      "great\n",
      "-PRON-\n",
      "pansy\n",
      "plant\n",
      "seed\n",
      "flower\n",
      "the\n",
      "great\n",
      "ask\n",
      "produce\n",
      "``\n",
      "love\n",
      "specialist\n",
      "size\n",
      "the\n",
      "people\n",
      "attacker\n",
      "energy\n",
      "rocket\n",
      "weapon\n",
      "nuclear\n",
      "complete\n",
      "'s\n",
      "city\n",
      "nation\n",
      "music\n",
      "the\n",
      "'s\n",
      "trout\n",
      "quintet\n",
      "musical\n",
      "present\n",
      "double\n",
      "bass\n",
      "symphonic\n",
      "give\n",
      "class\n",
      "junior\n",
      "dog\n",
      "show\n",
      "finals\n",
      "entry\n",
      "jr.\n",
      "westminster\n",
      "far\n",
      "year\n",
      "juniors\n",
      "speaker\n",
      "mrs.\n",
      "william\n",
      "h.\n",
      "long\n",
      "boat\n",
      "time\n",
      "water\n",
      "people\n",
      "united\n",
      "states\n",
      "recreational\n",
      "nation\n",
      "sea\n",
      "area\n",
      "find\n",
      "tappet\n",
      "bar\n",
      "lock\n",
      "move\n",
      "``\n",
      "the\n",
      "mechanical\n",
      "frame\n",
      "signal\n",
      "in\n",
      "set\n",
      "prevent\n",
      "lever\n",
      "short\n",
      "distance\n",
      "these\n",
      "side\n",
      "notch\n",
      "dog\n",
      "science\n",
      "formula\n",
      "hot\n",
      "world\n",
      "base\n",
      "mathematic\n",
      "math\n",
      "thing\n",
      "mean\n",
      "apply\n",
      "problem\n",
      "rodder\n",
      "a\n",
      "successful\n",
      "mathematical\n",
      "hanover\n",
      "good\n",
      "2-year\n",
      "old\n",
      "mile\n",
      "stable\n",
      "time\n",
      "kimberly\n",
      "laguerre\n",
      "tar\n",
      "heel\n",
      "monel\n",
      "be\n",
      "new\n",
      "-PRON-\n",
      "reader\n",
      "gun\n",
      "arm\n",
      "ve\n",
      "christmas\n",
      "decide\n",
      "time\n",
      "drop\n",
      "hint\n",
      "radio\n",
      "emission\n",
      "thermal\n",
      "moon\n",
      "planet\n",
      "atmosphere\n",
      "observation\n",
      "surface\n",
      "information\n",
      "the\n",
      "measurement\n",
      "characteristic\n",
      "wave\n",
      "length\n",
      "venus\n",
      "intensity\n",
      "arc\n",
      "anode\n",
      "energy\n",
      "the\n",
      "electric\n",
      "flow\n",
      "gas\n",
      "transfer\n",
      "reduce\n",
      "approximately\n",
      "total\n",
      "ablation\n",
      "mass\n",
      "velocity\n",
      "high\n",
      "electrode\n",
      "cooling\n",
      "tape\n",
      "block\n",
      "pull\n",
      "test\n",
      "rate\n",
      "af\n",
      "a\n",
      "fluid\n",
      "paste\n",
      "in\n",
      "use\n",
      "weight\n",
      "shear\n",
      "this\n",
      "af\n",
      "the\n",
      "paramagnetic\n",
      "effect\n",
      "dipole\n",
      "resonance\n",
      "field\n",
      "nuclear\n",
      "theory\n",
      "magnetic\n",
      "polycrystalline\n",
      "temperature\n",
      "electron\n",
      "line\n",
      "increase\n",
      "isotropic\n",
      "shift\n",
      "general\n",
      "second\n",
      "moment\n",
      "provide\n",
      "information\n",
      "detergent\n",
      "builder\n",
      "soap\n",
      "active\n",
      "polyphosphate\n",
      "synthetic\n",
      "sodium\n",
      "product\n",
      "the\n",
      "market\n",
      "today\n",
      "duty\n",
      "formulation\n",
      "household\n",
      "base\n",
      "tripolyphosphate\n",
      "build\n",
      "af\n",
      "reaction\n",
      "exchange\n",
      "the\n",
      "chlorine\n",
      "phase\n",
      "appear\n",
      "radical\n",
      "liquid\n",
      "quantum\n",
      "yield\n",
      "order\n",
      "light\n",
      "absorb\n",
      "gas\n",
      "obtain\n",
      "rate\n",
      "atom\n",
      "carbon\n",
      "molecule\n",
      "particle\n",
      "robertson\n",
      "effect\n",
      "the\n",
      "poynting\n",
      "force\n",
      "solar\n",
      "radiation\n",
      "sun\n",
      "size\n",
      "orbit\n",
      "increase\n",
      "whipple\n",
      "repulsive\n",
      "cause\n",
      "dust\n",
      "corpuscular\n",
      "gravitational\n",
      "semi\n",
      "axis\n",
      "biological\n",
      "weapon\n",
      "warfare\n",
      "man\n",
      "infectious\n",
      "disease\n",
      "period\n",
      "use\n",
      "agent\n",
      "research\n",
      "bw\n",
      "the\n",
      "effect\n",
      "incubation\n",
      "hand\n",
      "enemy\n",
      "group\n",
      "antibody\n",
      "cellulose\n",
      "sera\n",
      "a\n",
      "rh\n",
      "gradient\n",
      "anti\n",
      "sample\n",
      "technique\n",
      "study\n",
      "blood\n",
      "fractionation\n",
      "chromatography\n",
      "elution\n",
      "fractionate\n",
      "contain\n",
      "abo\n",
      "deae\n",
      "similar\n",
      "single\n",
      "b\n",
      "describe\n",
      "-PRON-\n",
      "bumblebee\n",
      "cold\n",
      "``\n",
      "queen\n",
      "``\n",
      "emerald\n",
      "high\n",
      "meeting\n",
      "cute\n",
      "macarthur\n",
      "peanut\n",
      "say\n",
      "wish\n",
      "linguist\n",
      "fact\n",
      "the\n",
      "degree\n",
      "john\n",
      "harvey\n",
      "-PRON-\n",
      "bari\n",
      "'s\n",
      "-PRON-\n",
      "``\n",
      "precisely\n",
      "feeling\n",
      "particular\n",
      "experience\n",
      "person\n",
      "dream\n",
      "dismiss\n",
      "school\n",
      "food\n",
      "``\n",
      "country\n",
      "psychological\n",
      "program\n",
      "good\n",
      "little\n",
      "'s\n",
      "november\n",
      "-PRON-\n",
      "railroad\n",
      "``\n",
      "vermont\n",
      "day\n",
      "1927\n",
      "mail\n",
      "rain\n",
      "-PRON-\n",
      "retire\n",
      "``\n",
      "where\n",
      "year\n",
      "how\n",
      "what\n",
      "retirement\n",
      "suddenly\n",
      "think\n",
      "ve\n",
      "go\n",
      "good\n",
      "important\n",
      "make\n",
      "privacy\n",
      "time\n",
      "sexual\n",
      "in\n",
      "marriage\n",
      "husband\n",
      "wife\n",
      "-PRON-\n",
      "place\n",
      "the\n",
      "partner\n",
      "take\n",
      "away\n",
      "pleasure\n",
      "joy\n",
      "but\n",
      "mutual\n",
      "relationship\n",
      "role\n",
      "act\n",
      "-PRON-\n",
      "give\n",
      "``\n",
      "houston\n",
      "title\n",
      "the\n",
      "new\n",
      "york\n",
      "golden\n",
      "girl\n",
      "police\n",
      "die\n",
      "play\n",
      "mickey\n",
      "jelke\n",
      "trial\n",
      "``\n",
      "lee\n",
      "squeeze\n",
      "-PRON-\n",
      "machine\n",
      "mrs.\n",
      "shaefer\n",
      "ask\n",
      "foot\n",
      "trouble\n",
      "know\n",
      "ozone\n",
      "-PRON-\n",
      "patient\n",
      "bus\n",
      "hospital\n",
      "good\n",
      "-PRON-\n",
      "``\n",
      "car\n",
      "say\n",
      "ticket\n",
      "tell\n",
      "be\n",
      "give\n",
      "number\n",
      "walk\n",
      "agency\n",
      "right\n",
      "``\n",
      "say\n",
      "-PRON-\n",
      "the\n",
      "man\n",
      "gun\n",
      "right\n",
      "door\n",
      "policeman\n",
      "corner\n",
      "thin\n",
      "roberta\n",
      "dave\n",
      "night\n",
      "-PRON-\n",
      "marty\n",
      "``\n",
      "eye\n",
      "squire\n",
      "chew\n",
      "gum\n",
      "cab\n",
      "do\n",
      "look\n",
      "answer\n",
      "``\n",
      "-PRON-\n",
      "say\n",
      "rourke\n",
      "be\n",
      "turn\n",
      "phone\n",
      "hour\n",
      "want\n",
      "shayne\n",
      "that\n",
      "n't\n",
      "get\n",
      "-PRON-\n",
      "roberts\n",
      "air\n",
      "step\n",
      "pause\n",
      "mickey\n",
      "try\n",
      "banister\n",
      "hand\n",
      "-PRON-\n",
      "``\n",
      "the\n",
      "drive\n",
      "coast\n",
      "town\n",
      "building\n",
      "``\n",
      "-PRON-\n",
      "angie\n",
      "mr.\n",
      "skyros\n",
      "trouble\n",
      "time\n",
      "and\n",
      "know\n",
      "n't\n",
      "want\n",
      "say\n",
      "think\n",
      "awkward\n",
      "smile\n",
      "pretty\n",
      "right\n",
      "away\n",
      "favor\n",
      "``\n",
      "-PRON-\n",
      "maude\n",
      "'s\n",
      "sarah\n",
      "happen\n",
      "oh\n",
      "n't\n",
      "open\n",
      "door\n",
      "lock\n",
      "key\n",
      "be\n",
      "coffee\n",
      "``\n",
      "-PRON-\n",
      "think\n",
      "n't\n",
      "try\n",
      "friend\n",
      "gilborn\n",
      "talk\n",
      "wife\n",
      "woman\n",
      "look\n",
      "black\n",
      "be\n",
      "say\n",
      "what\n",
      "'s\n",
      "``\n",
      "jury\n",
      "the\n",
      "election\n",
      "say\n",
      "fulton\n",
      "city\n",
      "grand\n",
      "atlanta\n",
      "'s\n",
      "primary\n",
      "irregularity\n",
      "term\n",
      "end\n",
      "charge\n",
      "report\n",
      "number\n",
      "law\n",
      "``\n",
      "committee\n",
      "daniel\n",
      "texas\n",
      "property\n",
      "banker\n",
      "personally\n",
      "measure\n",
      "million\n",
      "dollar\n",
      "year\n",
      "-PRON-\n",
      "``\n",
      "defendant\n",
      "trial\n",
      "statement\n",
      "judge\n",
      "parsons\n",
      "bellow\n",
      "indicate\n",
      "tell\n",
      "court\n",
      "the\n",
      "disclosure\n",
      "bellows\n",
      "client\n",
      "prejudicial\n",
      "-PRON-\n",
      "oslo\n",
      "the\n",
      "meeting\n",
      "organization\n",
      "understanding\n",
      "this\n",
      "step\n",
      "change\n",
      "in\n",
      "problem\n",
      "``\n",
      "trouble\n",
      "time\n",
      "director\n",
      "hawksley\n",
      "city\n",
      "defense\n",
      "cd\n",
      "mr.\n",
      "civil\n",
      "say\n",
      "east\n",
      "providence\n",
      "believe\n",
      "willing\n",
      "``\n",
      "program\n",
      "'s\n",
      "year\n",
      "-PRON-\n",
      "half\n",
      "salary\n",
      "``\n",
      "campaign\n",
      "hughes\n",
      "eisenhower\n",
      "republican\n",
      "party\n",
      "mitchell\n",
      "sen.\n",
      "jones\n",
      "r\n",
      "remark\n",
      "democratic\n",
      "gubernatorial\n",
      "candidate\n",
      "carcass\n",
      "republicanism\n",
      "club\n",
      "-PRON-\n",
      "monday\n",
      "state\n",
      "go\n",
      "democratic\n",
      "leader\n",
      "report\n",
      "wagner\n",
      "mayor\n",
      "organization\n",
      "party\n",
      "some\n",
      "mr.\n",
      "resentment\n",
      "district\n",
      "county\n",
      "running\n",
      "mate\n",
      "anti\n",
      "'s\n",
      "plan\n",
      "view\n",
      "pfaff\n",
      "company\n",
      "new\n",
      "-PRON-\n",
      "school\n",
      "promotion\n",
      "manager\n",
      "the\n",
      "orleans\n",
      "attend\n",
      "service\n",
      "``\n",
      "the\n",
      "city\n",
      "project\n",
      "hemphill\n",
      "bid\n",
      "$\n",
      "controller\n",
      "charge\n",
      "tuesday\n",
      "'s\n",
      "shortcut\n",
      "say\n",
      "hughes\n",
      "co.\n",
      "contract\n",
      "work\n",
      "varani\n",
      "-PRON-\n",
      "ierulli\n",
      "assistant\n",
      "district\n",
      "attorney\n",
      "monday\n",
      "e.\n",
      "d.\n",
      "portland\n",
      "help\n",
      "country\n",
      "build\n",
      "martin\n",
      "tell\n",
      "council\n",
      "way\n",
      "old\n",
      "man\n",
      "-PRON-\n",
      "street\n",
      "miss\n",
      "sound\n",
      "smell\n",
      "or\n",
      "call\n",
      "maggie\n",
      "baby\n",
      "'s\n",
      "head\n",
      "n't\n",
      "-PRON-\n",
      "food\n",
      "``\n",
      "-PRON-\n",
      "tolley\n",
      "'s\n",
      "picture\n",
      "read\n",
      "be\n",
      "laban\n",
      "mamma\n",
      "stay\n",
      "-PRON-\n",
      "doaty\n",
      "good\n",
      "``\n",
      "henrietta\n",
      "'s\n",
      "leave\n",
      "wish\n",
      "know\n",
      "hetty\n",
      "japanese\n",
      "the\n",
      "momoyama\n",
      "come\n",
      "miyagi\n",
      "prefecture\n",
      "island\n",
      "-PRON-\n",
      "man\n",
      "girl\n",
      "``\n",
      "-PRON-\n",
      "'s\n",
      "perhaps\n",
      "buzz\n",
      "say\n",
      "go\n",
      "``\n",
      "spencer\n",
      "captain\n",
      "say\n",
      "alexander\n",
      "moment\n",
      "-PRON-\n",
      "black\n",
      "straight\n",
      "young\n",
      "the\n",
      "stride\n",
      "wear\n",
      "long\n",
      "high\n",
      "pass\n",
      "market\n",
      "place\n",
      "-PRON-\n",
      "``\n",
      "dream\n",
      "and\n",
      "will\n",
      "the\n",
      "imagine\n",
      "begin\n",
      "big\n",
      "maybe\n",
      "pole\n",
      "-PRON-\n",
      "the\n",
      "book\n",
      "jacket\n",
      "spot\n",
      "drawing\n",
      "detail\n"
     ]
    }
   ],
   "source": [
    "common_word_lists = []\n",
    "for article in labels_df['spacy_articles']:\n",
    "    common_word_lists.append(bag_of_words(article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_word_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in common_word_lists for item in sublist]\n",
    "\n",
    "common_words = list(set().union(flat_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "864"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_texts = labels_df.loc[:, ['spacy_articles', 'info']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 10\n",
      "Processing row 20\n",
      "Processing row 30\n",
      "Processing row 40\n",
      "Processing row 50\n",
      "Processing row 60\n",
      "Processing row 70\n",
      "Processing row 80\n",
      "Processing row 90\n",
      "Processing row 100\n"
     ]
    }
   ],
   "source": [
    "word_counts = bow_features(the_texts, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>japanese</th>\n",
       "      <th>lock</th>\n",
       "      <th>papa</th>\n",
       "      <th>grow</th>\n",
       "      <th>or</th>\n",
       "      <th>nations</th>\n",
       "      <th>purchasing</th>\n",
       "      <th>manager</th>\n",
       "      <th>seed</th>\n",
       "      <th>woman</th>\n",
       "      <th>...</th>\n",
       "      <th>pass</th>\n",
       "      <th>hot</th>\n",
       "      <th>fluid</th>\n",
       "      <th>theatre</th>\n",
       "      <th>century</th>\n",
       "      <th>rate</th>\n",
       "      <th>fix</th>\n",
       "      <th>technical</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Dan, Morgan, told, himself, he, would, forget...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Gavin, paused, wearily, ., ``, You, ca, n't, ...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, sentry, was, not, dead, ., He, was, ,, i...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(``, So, it, was, n't, the, earthquake, that, ...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(She, was, carrying, a, quirt, ,, and, she, st...</td>\n",
       "      <td>adventure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  866 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  japanese lock papa grow or nations purchasing manager seed woman  \\\n",
       "0        0    0    0    0  0       0          0       0    0     0   \n",
       "1        0    0    0    0  0       0          0       0    0     0   \n",
       "2        0    0    0    0  0       0          0       0    0     0   \n",
       "3        0    0    0    0  0       0          0       0    0     0   \n",
       "4        0    0    0    0  0       0          0       0    0     0   \n",
       "\n",
       "      ...     pass hot fluid theatre century rate fix technical  \\\n",
       "0     ...        0   0     0       0       0    0   0         0   \n",
       "1     ...        0   0     0       0       0    0   0         0   \n",
       "2     ...        0   0     0       0       0    0   0         0   \n",
       "3     ...        0   0     0       0       0    0   0         0   \n",
       "4     ...        0   0     0       0       0    0   0         0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Dan, Morgan, told, himself, he, would, forget...   adventure  \n",
       "1  (Gavin, paused, wearily, ., ``, You, ca, n't, ...   adventure  \n",
       "2  (The, sentry, was, not, dead, ., He, was, ,, i...   adventure  \n",
       "3  (``, So, it, was, n't, the, earthquake, that, ...   adventure  \n",
       "4  (She, was, carrying, a, quirt, ,, and, she, st...   adventure  \n",
       "\n",
       "[5 rows x 866 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf-idf thing is next\n",
    "- Then do the supervised learning on both sets of features individually\n",
    "- pick a model and try to improve it is last."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then do unit 4 capstone.\n",
    "\n",
    "- Try clustering\n",
    "- Unsupervised feature generation\n",
    "- Attempt combos of supervised and unsupervised techniques to try to get best results\n",
    "- Write-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
