{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give Me Some Credit: Predicting loan repayment delinquencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "Can we look at a candidate application and tell if they are going to pay back their loans on time with reasonable accuracy?\n",
    "\n",
    "Yes.\n",
    "\n",
    "### Introduction\n",
    "This dataset comes from a [2011 Kaggle competiton](https://www.kaggle.com/c/GiveMeSomeCredit).\n",
    "\n",
    "Here is the competition overview with one corrected typo:\n",
    "\n",
    "\"Banks play a crucial role in market economies. They decide who can get finance and on what terms and can make or break investment decisions. For markets and society to function, individuals and companies need access to credit. \n",
    "\n",
    "Credit scoring algorithms, which make a guess at the probability of default, are the method banks use to determine whether or not a loan should be granted. This competition requires participants to improve on the state of the art in credit scoring, by predicting the probability that somebody will experience financial distress in the next two years.\n",
    "\n",
    "The goal of this competition is to build a model that (lenders) can use to help make the best financial decisions.\"\n",
    "\n",
    "Top scores on the leaderboard were roughly .86."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import fancyimpute\n",
    "\n",
    "from fancyimpute import KNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "from sklearn import ensemble\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# The PipeLine\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competiton training dataset and outcome variable\n",
    "credit = pd.read_csv('cs-training.csv', index_col=0)\n",
    "delinq = credit.SeriousDlqin2yrs\n",
    "test_data = pd.read_csv('cs-test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting data into stratified train/test groups\n",
    "X_train, X_test_dropna, y_train, y_test = train_test_split(credit,\n",
    "                                                    delinq, \n",
    "                                                    test_size=.2, \n",
    "                                                    stratify=delinq, \n",
    "                                                    random_state=24\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Data Exploration Summary\n",
    "A link to my data exploration and explanations of my decisions can be found [here.](https://github.com/Lukede9/Thinkful/blob/master/Bootcamp/Unit%203/Capstone/Capstone%20EDA.ipynb) Summary:\n",
    "\n",
    "#### Missing Data\n",
    "The was missing data in the monthly income and number of dependents columns.\n",
    "- Roughly 20% of borrowers did not report monthly income.\n",
    "- Roughly 2.5% did not report their # of dependents.\n",
    "\n",
    "Many variables had strange outliers that I will treat as missing and impute. These include:\n",
    "- age < 21\n",
    "- NumberOfTime30-59DaysPastDueNotWorse > 13\n",
    "- NumberOfTime60-89DaysPastDueNotWorse > 11\n",
    "- NumberOfTimes90DaysLate > 17\n",
    "- RevolvingUtilizationOfUnsecuredLines > 2\n",
    "- NumberRealEstateLoansOrLines > 30\n",
    "- DebtRatio > 2\n",
    "- MonthlyIncome > 10000\n",
    "- NumberOfDependents > 6\n",
    "\n",
    "#### Multi-collinearity\n",
    "- The three columns about lateness are highly redundant.\n",
    "- The number of lines and loans has a correlation with number of real estate lines and loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with outliers and missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outcome variable from DataFrame\n",
    "def df_remove_outcome(df):\n",
    "    df = df.drop(columns='SeriousDlqin2yrs')\n",
    "    return df\n",
    "# Handling outliers in age\n",
    "def age_nan(age):\n",
    "    if age <21:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return age\n",
    "    \n",
    "def df_age_nan(df):\n",
    "    df['age'] = df['age'].apply(lambda x: age_nan(x))\n",
    "    return df\n",
    "\n",
    "# Handling outliers in RevolvingUtilizationOfUnsecuredLines\n",
    "def rev_nan(rev):\n",
    "    if rev > 2:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return rev\n",
    "    \n",
    "def df_rev_nan(df):\n",
    "    df['RevolvingUtilizationOfUnsecuredLines'] = df['RevolvingUtilizationOfUnsecuredLines'].apply(lambda x: rev_nan(x))\n",
    "    return df\n",
    "\n",
    "# Handling outliers in NumberRealEstateLoansOrLines\n",
    "def real_estate_nan(real_estate):\n",
    "    if real_estate > 30:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return real_estate\n",
    "\n",
    "def df_real_estate_nan(df):\n",
    "    df['NumberRealEstateLoansOrLines'] = df['NumberRealEstateLoansOrLines'].apply(lambda x: real_estate_nan(x))\n",
    "    return df\n",
    "\n",
    "# Handling outliers in DebtRatio\n",
    "def debt_nan(debt):\n",
    "    if debt > 2:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return debt\n",
    "    \n",
    "def df_debt_nan(df):\n",
    "    df['DebtRatio'] = df['DebtRatio'].apply(lambda x: debt_nan(x))\n",
    "    return df\n",
    "\n",
    "# Handling outliers in MonthlyIncome\n",
    "def income_nan(income):\n",
    "    if income > 10000:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return income\n",
    "\n",
    "def df_income_nan(df):\n",
    "    df['MonthlyIncome'] = df['MonthlyIncome'].apply(lambda x: (income_nan(x)))\n",
    "    return df\n",
    "\n",
    "# Handling outliers in NumberOfTime30-59DaysPastDueNotWorse\n",
    "def late_30(count):\n",
    "    if count > 13:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return count\n",
    "    \n",
    "def df_late_30(df):\n",
    "    df['NumberOfTime30-59DaysPastDueNotWorse'] = df['NumberOfTime30-59DaysPastDueNotWorse'].apply(lambda x: late_30(x))\n",
    "    return df\n",
    "\n",
    "# Handling outliers in NumberOfTime60-89DaysPastDueNotWorse\n",
    "def late_60(count):\n",
    "    if count > 11:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return count\n",
    "    \n",
    "def df_late_60(df):\n",
    "    df['NumberOfTime60-89DaysPastDueNotWorse'] = df['NumberOfTime60-89DaysPastDueNotWorse'].apply(lambda x: late_60(x))\n",
    "    return df\n",
    "\n",
    "# Handling outliers in NumberOfTimes90DaysLate\n",
    "def late_90(count):\n",
    "    if count > 17:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return count\n",
    "    \n",
    "def df_late_90(df):\n",
    "    df['NumberOfTimes90DaysLate'] = df['NumberOfTimes90DaysLate'].apply(lambda x: late_90(x))\n",
    "    return df\n",
    "\n",
    "# Handling outliers in NumberOfDependents\n",
    "def depend(count):\n",
    "    if depend > 6:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return depend\n",
    "    \n",
    "def df_depend(df):\n",
    "    df['NumberOfDependents'] = df['NumberOfDependents'].apply(lambda x: depend(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace all outliers with NaN at once\n",
    "def nan(df):\n",
    "    df = df_remove_outcome(df)\n",
    "    df = df_age_nan(df)\n",
    "    df = df_rev_nan(df)\n",
    "    df = df_real_estate_nan(df)\n",
    "    df = df_debt_nan(df)\n",
    "    df = df_income_nan(df)\n",
    "    df = df_late_30(df)\n",
    "    df = df_late_60(df)\n",
    "    df = df_late_90(df)\n",
    "    df = df_depend(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing missing values with FancyImpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean mask of nulls\n",
    "def nan_tf(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = np.isnan(df[col])\n",
    "    return df\n",
    "\n",
    "# Returns DataFrame, nulls filled using KNN, k=3\n",
    "def df_fancyimpute(df):\n",
    "    df_mask = nan_tf(df.copy())\n",
    "    filled = KNN(k=3).fill(df, df_mask)\n",
    "    filled = pd.DataFrame(filled)\n",
    "    filled.columns = df.columns\n",
    "    return filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most obvious new features to create are just combining the correlated features we already have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take in DF and return it with new column of combined defaults feature\n",
    "def df_combined_lates(df):\n",
    "    df['combined_lates'] = df['NumberOfTime30-59DaysPastDueNotWorse'] + \\\n",
    "    df['NumberOfTime60-89DaysPastDueNotWorse'] + \\\n",
    "    df['NumberOfTimes90DaysLate']\n",
    "    return df\n",
    "\n",
    "# Take in DF and return it with new column of combined lines feature\n",
    "def df_combined_lines(df):\n",
    "    df['combined_lines'] = df['NumberRealEstateLoansOrLines'] + \\\n",
    "    df['NumberOfOpenCreditLinesAndLoans']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns DataFrame with new features for lateness and loans\n",
    "def df_new_features(df):\n",
    "    df = df_combined_lates(df)\n",
    "    df = df_combined_lines(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Tuning\n",
    "The models that I will be testing out are Logistic Regression, K-Nearest Neighbors, Random Forest, and Gradient Boosting. I chose these because they will still perform with non-normal data.\n",
    "\n",
    "The measure of performance is the area under the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best model and fine tune it with undersampling and GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results using roc seaborn visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize it all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
