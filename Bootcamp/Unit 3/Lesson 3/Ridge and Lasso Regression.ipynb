{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data again. Keep air quality data, drop the index column\n",
    "# and any missing data columns.\n",
    "df = pd.read_csv(\n",
    "    'Default.csv'\n",
    ").iloc[:,1:].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.185599</td>\n",
       "      <td>-0.645936</td>\n",
       "      <td>-0.218835</td>\n",
       "      <td>0.813187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.185599</td>\n",
       "      <td>1.548141</td>\n",
       "      <td>-0.037616</td>\n",
       "      <td>-1.605496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.185599</td>\n",
       "      <td>-0.645936</td>\n",
       "      <td>0.492410</td>\n",
       "      <td>-0.131212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.185599</td>\n",
       "      <td>-0.645936</td>\n",
       "      <td>-0.632893</td>\n",
       "      <td>0.164031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.185599</td>\n",
       "      <td>-0.645936</td>\n",
       "      <td>-0.102791</td>\n",
       "      <td>0.370915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    default   student   balance    income\n",
       "0 -0.185599 -0.645936 -0.218835  0.813187\n",
       "1 -0.185599  1.548141 -0.037616 -1.605496\n",
       "2 -0.185599 -0.645936  0.492410 -0.131212\n",
       "3 -0.185599 -0.645936 -0.632893  0.164031\n",
       "4 -0.185599 -0.645936 -0.102791  0.370915"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recode strings to numeric.\n",
    "df['default'] = np.where(df['default']=='Yes', 1, 0)\n",
    "df['student'] = np.where(df['student']=='Yes', 1, 0)\n",
    "names = df.columns\n",
    "df = pd.DataFrame(preprocessing.scale(df), columns=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training and test sizes.\n",
    "trainsize = int(df.shape[0] / 2)\n",
    "df_train = df.iloc[:trainsize, :].copy()\n",
    "df_test = df.iloc[trainsize:, :].copy()\n",
    "\n",
    "\n",
    "Y_train = df_train['income'].values.reshape(-1, 1)\n",
    "X_train = df_train.loc[:, ~(df_train.columns).isin(['income'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some new features to capture potential quadratic and cubic\n",
    "# relationships between solar radiation and day or temperature.\n",
    "df_train['balance_student'] = df_train['balance'] * df_train['student']\n",
    "df_train['balance_default'] = df_train['balance'] * df_train['default']\n",
    "df_train['student_default'] = df_train['student'] * df_train['default']\n",
    "df_train['balance_sqrt'] = (df_train['balance'] + 100) ** .5\n",
    "df_train['balance2'] = (df_train['balance'] + 100) ** 2\n",
    "df_train['balance3'] = (df_train['balance'] + 100) ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = df_train.loc[:, ~(df_train.columns).isin(['income'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the simpler model with smaller coefficients.\n",
    "Y_test = df_test['income'].values.reshape(-1, 1)\n",
    "X_test = df_test.loc[:, ~(df_test.columns).isin(['income'])]\n",
    "\n",
    "# Test the more complex model with larger coefficients.\n",
    "df_test['balance_student'] = df_test['balance'] * df_test['student']\n",
    "df_test['balance_default'] = df_test['balance'] * df_test['default']\n",
    "df_test['student_default'] = df_test['student'] * df_test['default']\n",
    "df_test['balance_sqrt'] = (df_test['balance'] + 100) ** .5\n",
    "df_test['balance2'] = (df_test['balance'] + 100) ** 2\n",
    "df_test['balance3'] = (df_test['balance'] + 100) ** 3\n",
    "X_test2 = df_test.loc[:, ~(df_test.columns).isin(['income'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² for the model with few features:\n",
      "0.450062579301185\n",
      "\n",
      "Parameter estimates for the model with few features:\n",
      "[-0.         -0.40657726 -0.          0.00114596]\n",
      "\n",
      "R² for the model with many features:\n",
      "0.44363376712897085\n",
      "\n",
      "Parameter estimates for the model with many features:\n",
      "[ 0.00000000e+00 -3.89351238e-01  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -2.77688887e-04\n",
      " -7.09158792e-07  3.48711577e+00]\n"
     ]
    }
   ],
   "source": [
    "# Small number of parameters.\n",
    "lass = linear_model.Lasso(alpha=.35)\n",
    "lassfit = lass.fit(X_train, Y_train)\n",
    "print('R² for the model with few features:')\n",
    "print(lass.score(X_train, Y_train))\n",
    "origparams = np.append(lassfit.coef_, lassfit.intercept_)\n",
    "print('\\nParameter estimates for the model with few features:')\n",
    "print(origparams)\n",
    "\n",
    "# Large number of parameters.\n",
    "lassBig = linear_model.Lasso(alpha=.35)\n",
    "lassBig.fit(X_train2, Y_train)\n",
    "print('\\nR² for the model with many features:')\n",
    "print(lassBig.score(X_train2, Y_train))\n",
    "origparams = np.append(lassBig.coef_, lassBig.intercept_)\n",
    "print('\\nParameter estimates for the model with many features:')\n",
    "print(origparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44553225151184195\n",
      "0.4380466345914476\n"
     ]
    }
   ],
   "source": [
    "print(lass.score(X_test, Y_test))\n",
    "\n",
    "print(lassBig.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization parameter: Lasso\n",
    "\n",
    "The $\\lambda$ for lasso can var between 0 (no penalty, acts like OLS) and infinity.  If $\\lambda$ is too large, all parameters will be set to zero.  \n",
    "\n",
    "Create a plot below of how $R^2$ varies across different values of $\\lambda$ for ridge and lasso regression. Use logic and code similar to the ridge regression demonstration above, and base your plot on the X_train2 feature set.\n",
    "\n",
    "Do lasso and ridge yield the same $R^2$ for a given lambda value?\n",
    "\n",
    "Submit your work and discuss the results with your mentor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso(alphas, x, y):\n",
    "    '''Alphas are list of alphas (lambdas), x is training \n",
    "    data and y is training target, returns dataframe with coefficients for new alphas'''    \n",
    "    \n",
    "    special_lst = []\n",
    "    for alpha in alphas:\n",
    "        lasseau = linear_model.Lasso(alpha=alpha)\n",
    "        lasseau.fit(x, y)\n",
    "        special_lst.append(lasseau.coef_)\n",
    "        \n",
    "    special_df = pd.DataFrame(special_lst)\n",
    "    \n",
    "    special_df.columns = x.columns\n",
    "    special_df['alpha'] = alphas\n",
    "    \n",
    "    return special_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphanator = list(map(lambda x: x/100.0, range(1, 50, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_alpha = lasso(alphanator, X_train2, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>balance_student</th>\n",
       "      <th>balance_default</th>\n",
       "      <th>student_default</th>\n",
       "      <th>balance_sqrt</th>\n",
       "      <th>balance2</th>\n",
       "      <th>balance3</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.749175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-1.452173e-09</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.738715</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.037485e-08</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.728221</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-1.421844e-08</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.717632</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-1.931312e-08</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.707044</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-2.440781e-08</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default   student  balance  balance_student  balance_default  \\\n",
       "0      0.0 -0.749175      0.0             -0.0         0.004649   \n",
       "1      0.0 -0.738715     -0.0             -0.0         0.002006   \n",
       "2      0.0 -0.728221     -0.0             -0.0         0.000000   \n",
       "3      0.0 -0.717632     -0.0             -0.0         0.000000   \n",
       "4      0.0 -0.707044     -0.0             -0.0         0.000000   \n",
       "\n",
       "   student_default  balance_sqrt  balance2      balance3  alpha  \n",
       "0             -0.0           0.0 -0.000000 -1.452173e-09   0.01  \n",
       "1             -0.0          -0.0 -0.000002 -1.037485e-08   0.02  \n",
       "2             -0.0          -0.0 -0.000007 -1.421844e-08   0.03  \n",
       "3             -0.0          -0.0 -0.000018 -1.931312e-08   0.04  \n",
       "4             -0.0          -0.0 -0.000029 -2.440781e-08   0.05  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_alpha.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VOXZ+P/PmZlsZIEQ2dGy1UuqP1zwK251e2hFKlSxCFKloCLWR6lQFcQKgS+kLihVeUDj8gPZyQ9sKw9abH2JCkUrVSsiNwUESq2yJhDIOnN+f5zJMIQsJyGzJHO9Xy/M5KzXmcS5cp/7Ptdt2baNUkop5YYn1gEopZRqPjRpKKWUck2ThlJKKdc0aSillHJNk4ZSSinXNGkopZRyTZOGUkop1zRpKKWUck2ThlJKKdd8sQ6gqfXr18/u0qVLrMNQSqlm5csvvzxgjGlX33YtLml06dKFVatWxToMpZRqVkRkt5vt9PaUUkop1zRpKKWUck2ThlJKKddaXJ+GUip6Kioq2Lt3L6WlpbEORbmUmppK165dSUpKatT+mjSUUo22d+9eMjMz6datG5ZlxTocVQ/btjl48CB79+6le/fujTqG3p5SSjVaaWkpOTk5mjCaCcuyyMnJOa2WoSYNpdRp0YTRvJzuz0uTRlDlwYMcWbs21mEopVRc06QRdGTNW/x73K/wFxfHOhSlVCOUlZVx3XXX1bp+woQJ3HLLLezYscP1Mffu3cutt94KwN/+9je2bt162nE2d5o0gjxpqQAEiopiHIlSKhI2bNjAypUr6dmzZ6P2X7lyJfv27WviqJofHT0V5MnIBMBfXEzjBqIpldhWbtrLik/+1aTHvPXiM7mlb9da1x87doyHHnqII0eOcNZZZwFgjGHGjBkAtGnThry8PJ555hmKi4v55S9/ydNPP81jjz3G0aNH2bdvHyNGjGDEiBHccccd5Obm0rNnT5YuXcqBAwe4+eabAdi8eTMffPABX375Jb169aJz585Nep3NibY0grxZTtIIHDkS40iUUm4tW7aMs88+m8WLFzN8+HAAHn/8caZOncrChQu56qqreOWVV8jNzaV169bMmzeP3bt385Of/ITXXnuNV199lfnz59d7nvPOO48f/vCHPPzwwwmdMEBbGiGezGBL46j2aSjVGLf07VpnqyASdu3axdVXXw3A+eefj8/nY8eOHUybNg1wHj7s1q3bSfucccYZLFiwgLVr15KRkUFlZeUpx7VtO+KxN1eaNII8GRkABIqPxjgSpZRbPXv25LPPPqN///5s2bKFyspKunfvzpNPPknnzp3ZtGkT+/fvP2mf1157jQsuuIARI0awceNG1q1bB0BycjL79++nZ8+ebNmyhQ4dOpy0n2VZmkzQpBHizcoCwH9Ek4ZSzcVtt93GI488wm233UaPHj1ISkoiNzeXiRMnUllZiWVZzJw586R9rr32WmbMmMGaNWvIzMzE6/VSXl7OyJEjmTZtGp07d6Z9+/annOv8889n1qxZdO3atdGd6S2B1dIy55AhQ+zGzKcRKC/H9Dmfdg/+ijPuvTcCkSnV8nz11Vf07t071mGoBqrp5yYim4wxF9e3r3aEB3mSk7FSUrSloZRSddCkEcaTmUngqCYNpZSqjSaNMN6MDPzaEa6UUrXSpBHGk5VFQG9PKaVUrTRphNGWhlJK1U2TRhhtaSilVN00aYTxZmpLQ6nmZNWqVcyaNave7T766CPGjx8fhYhaPk0aYTwZmQS0jIhSStVKnwgP483KxC4txS4vx0pOjnU4SjUvny2FTxc17TEvvB0uuK3u0372Gb/4xS8oLi7mgQceoLS0lMWLF4eeCJ8zZ85J2y9atIi1a9dSUlJCdnY2c+bMYfXq1axbt47S0lL27NnDmDFjGDJkCJ9//jl5eXkEAgE6dOjArFmz2L179ylVdDODtesSgbY0woSXR1dKNQ9paWnMnz+f/Px8pk+fzq5du8jPz2fp0qX06tWLDz/8MLRtIBCgsLCQ+fPnU1BQgN/v54svvgCguLiYl156iXnz5pGfnw/AlClTyMvLo6CggKuvvpodO3bUWEU3kWhLI8xJ5dHbto1xNEo1MxfcVm+rIBL69u2LZVnk5OSQmZmJz+dj4sSJpKens3PnTi644ILQth6Ph6SkJCZMmECrVq349ttvQ1VuzznnHAA6depEeXk5AAcOHAjVmRo6dChAvVV0WzpNGmG0PLpSzU9VS2H//v0cPXqUBQsW8N577wEwevTokyrTbt26lT//+c8UFBRQUlLCkCFDQustyzrl2O3bt2fXrl1069aN/Px8unfvXm8V3ZZOk0YYLY+uVPNTWlrKyJEjOX78ODNnzmTZsmUMGzYMn89HVlYW+/bto2tXZ56P733ve6SlpYUmbGrXrl2dU7hOmzaNyZMn4/F4aNeuHaNGjaJTp051VtFt6bTKbZjSrVv5+qab6fLcc2Rd/+Mmjkyplker3DZPWuW2iVR1hGtLQymlahaR21Mi4gHmAucDZcDdxpjtYevHAGOBSmCGMWa1iJwBLAHSgG+A0caY42HH+1/gD8aYFyMRM5zoCPdrpVullKpRpFoaNwGpxpjLgEnAM1UrRKQjMA64Arge+K2IpABTgCXGmB8Cn+IklSozgOwIxRriSU8H0FIiSilVi0gljSuBtwGMMRuB8PtklwDrjTFlxpgiYDvQJ3wf4C2gP4CI/AwIhK2LGMvrxZOerqVElFKqFpFKGllAUdj3fhHx1bLuKNC62vKjQGsROQ8YgdMKiQotWqiUUrWL1JDbI0D4c/UeY0xlLesygcKw5SVhy0YCXYB3gW5AuYjsMsZErNWh5dGVUqp2kUoa64FBwAoRuRT4Imzdx8BMEUkFUoDewObgPgOB+cANwAfGmCerdhKRXODbSCYMCLY09OE+pZSqUaRuT70BlIrIBmA2MF5EJojIYGPMt8DzwAc4LYjHjDGlOJ3dw0VkPXAZMKeWY0eUNyMD/9EjsTi1UqqBmmNp9MLCQt58803X248fP56PPvqowedZtKiJi0cGRaSlYYwJAPdWW7w1bP3LwMvV9vkOGFDHMXObMMRaeTIzCezcGY1TKdWi/HHHH3njn2806TFv/v7NDO45uEmPGWvGGN59910GDRoU0fPMmzeP22+/vcmPq2VEqvFmZToFC5VSzUI8l0Zfu3YtL7/8Mj6fj/bt2zN79mxefPFFtm7dyvLly/n0008ZOHAgV111Fe+//z5r1qzhiSeeYPHixRQUFNCuXTsOHjwIOMURp06dyu7duwkEAjz44IP069ePQYMGcckll2CMwbIs5s6dy6JFiygqKiI3N5fc3NymfcNt225R/26++Wb7dHz3zLP2lh+cawcCgdM6jlKJYMuWLTE9/8qVK+27777bDgQC9oEDB+xrr73Wnjdvnn38+HHbtm378ccft//whz/YGzdutB988EHb7/fbL7zwgu33+23btu0777zT/uSTT+yVK1fad955p23btv3111/b119/vW3btj148GB7+/bttm3b9ooVK+zNmzfbQ4cOtf/5z3+Glj377LO1xvfAAw/Yb731lm3btv3GG2/YRUVFoVhs27YnTpxor1u3zrZt2163bp09ceJEe//+/faPf/xju6yszC4vL7dvvPFGe+PGjfbixYvtp556yrZt2z506JA9cOBA27Zt+9prr7U3bdpk27ZtT5gwwV69erVt27Z9+eWX1xpXTT+3s88++xPbxWestjSq8WZlgt+PXVKC1apVrMNRStUjnkujP/roo7z00kssWrSIHj160L9//1q3tYN1APfs2UOvXr1IDk4E16dPHwC2bdvGpk2b+Mc//gFAZWUlhw4dAuAHP/hBKPaysjK3b12jaNKoJjQR09GjeDRpKBX34rk0+vLly3nggQfIyclhypQpvPPOO3Tt2pVAIABAcnJyaP8tW7YA0K1bN7Zv305paSlJSUl89dVXDB48mB49etCxY0fuvfdeSktLmTdvHm3atKk19vDrbkqaNKrxZAbLox89Ch06xDgapVR94rk0ep8+fRg7dizp6em0atWKa665hvLycrZt28b8+fMZOnQokydP5s033wy1WNq2bcuYMWMYPnw4bdu2JS0tDYDhw4fzm9/8httvv53i4mJGjBiBx1P7ANiePXvy0EMPuRpd1hBaGr2a4g8+4F9j7uF7S5bQ6qILmzAypVoeLY3ePJ1OaXRtaVSjEzEppRqivLycu+6665Tl3bt3Z/r06TGIKLI0aVTjzcoCtDy6Usqd5ORkFi5cGOswokYnYaomNBGTJg2llDqFJo1qvMGOcG1pKKXUqTRpVGOlpYHPp+XRlVKqBpo0qrEsS8ujK6VULTRp1EDLoyvVPDSnKrfvv/8+kyZNqnV9UVERN998M6NHj27QccPfg+XLl1NRUXFacdZHR0/VQMujK9Vwhb//PUUrG/+MVE1a3zKENjfd1KTHjFfbtm2ja9euvPDCC40+xksvvcRNEX6/NGnUwJOZqS0NpZqJeK5yu2PHDiZPnkxaWhppaWm0bt0agLfeeov58+fj8Xjo27cv48aNY8aMGezbt4/nn3+eAQMG8MQTT+D3+zl8+DC5ublcdNFFXHHFFaxfvx5w5tmoerIdoKCggP379zN+/Hjmzp0bibca0KRRI29WJuW7dsU6DKWalTY33RSTVkFaWhr5+fkcOnSIoUOHcuutt5Kfn09aWhpTpkzhww8/pEOwJFAgEKCwsDD0gX3XXXeFalcVFxfz6quvsmvXLu69916GDBnClClTePbZZ+nZsycFBQWhYoV5eXn06tWLgoICXnnllVpvfT311FOMGzeOK664gvz8fHbu3ElhYSEvvPACK1euJC0tjYcffpi//e1vTJ48mWXLljFu3DjWrFnDxIkTERHefPNNVq1axUUXXVTn+zB06FDmzZvH7Nmzm/YNrqbepCEi5wHzgGxgEbDZGLM6olHFmCcjE7+2NJRqFuK5yu2uXbtCVWovuugidu7cyZ49ezh06BD33HMPAMeOHWPPnj306NEjtF/79u2ZO3cuqampHDt2jIxgpYpwsSoB5aal8RwwGmemvVeBt4AWnTS8WZn6cJ9SzUQ8V7nt2bMnn376KVdddRWbN28GoGvXrnTq1InXXnuNpKQkVq1aRe/evTkSNvnbzJkzmTVrFj179uT555/n3//+N+CUQz927BhJSUls3779lPNZlhWqoBsprm5PGWO2i4htjNkvIi3+09STkUng2DFsvx/L6411OEqpOsRzldtJkyYxceJEXn31Vdq2bUtKSgpt27Zl1KhR3HHHHfj9frp06cINN9wQmicDYPDgwfzqV78iKyuLjh07cvjwYQBGjhzJsGHD6Nq1K507dz7lfBdffDH33HMPr7/+eo1JsCnUW+VWRAqAPwN3ArOBYcaYmyMSTRM43Sq3AAfnz2ffE09y9kcb8QY7rpRSp9Iqt81TpKvc3gVMBg4AF+MkjxbNm1lVtLBYk4ZSqk5a5fZUvwIeN8ZUAIjIE0DtT6i0ACcmYjoCdIltMEqpuKZVbk81DvijiKQHv78kgvHEBS2PrpRSNXOTNDYDLwB/EpH2QMua6q8GWh5dKaVq5nb01BoRKcYZbtvi61VpeXSllKqZmwSwDsAY8z5wN5AU0YjigCd4e0pLiSil1MlqTRoi0jX4comInC0iZwPHgCFRiSyGvBlVLQ0tWqhUc7No0SLX2y5durRRBQLfeecdvvvuO1fb7tixgzvuuKPW9ZWVldxxxx0MHz6coqIi1zGEV+5tSDynq67bUxOC/16qttwGrotYRHHASkrCSkvTloZSDbB143/4av1/mvSYva/oxDmXdmrQPvPmzeP2229v0jiqe/3118nNzQ3VtDod+/bt49ixY5zO82VNGU99ak0axpgJwa/XVi0TkTONMf+KeFRxQMujKxX/vv76ax599FF8Ph+BQIDLL7+coqIicnNz6dOnDzt37uShhx6irKyMG264gXfffZdPPvmEvLw8srKy8Hq9odpUCxcuZPXq1ViWxcCBAxk5ciSTJk0iOTmZf//73+zbt48nnniC/fv389VXXzFx4kSWLFlCcnLyKXHt27ePhx56CNu2adeuXWj5xx9/zOzZs/F6vZx55plMnz6dqVOnsmvXLqZMmcJ9991Hbm4uZWVl7N+/nwcffJD+/ftz3XXX8dZbb5GSksKsWbPo0aMHXbo4jwO899579cbTlNwULHwYKATaAKNF5O2qhNKSaXl0pRrmnEsb3io4XRs2bKBPnz48/PDDfPLJJ+Tk5LB06VJyc3Nr/ct92rRpPP/883Tv3p2pU6cCsH37dtasWcOSJUsAp2bVlVdeCUDnzp2ZPn06K1asYPny5UyfPp3evXuTm5tb6wf0iy++yI033sitt97KmjVrWLp0KbZt8/jjj7NkyRJycnL43e9+xxtvvMHUqVOZMGEC06dPZ8OGDYwePZp+/frx97//nRdeeIH+/fvX+R5cc8019cbTlNx0hN8CLABuMMb8ALgwsiHFB2+mFi1UKt797Gc/Iysri7vvvpvFixfjraVWXHi5pAMHDtC9e3eAULnxbdu28c033zBq1ChGjRpFYWEhu3fvBgiV2+jYsWOo+m19qle3BTh06BD79u3jwQcf5I477mD9+vWhQoRV2rVrx/Lly3n44YdZtmxZqAJvbdcSC26Shh/oCFT1sqRFLpz44cnM1CG3SsW5v/zlL/Tt25cFCxYwYMAAXnnlldCHakpKSqgC7Zdffhnap0OHDuzYsQM4USG3R48e9OrVi9dff52FCxcyZMgQRASoufqtZVl1fnhXVbcNP0d2djYdO3Zk7ty5LFy4kHvvvZdLL730pP2ee+45fvrTn/L000/Tr1+/0DmSk5PZt28ftm2zdevWBsfTlNw8p/Fe8N/tIjIb+N/6dhARDzAXOB8oA+42xmwPWz8GGAtUAjOMMatF5AxgCU5S+gYYbYw5LiL/DYzC6YCfZYxZ4frqToM3K5OKvXujcSqlVCOdd955TJw4kXnz5hEIBHj00UfZu3cvDz30EFOmTGHp0qXcdtttnHvuuaSnO0Utpk+fziOPPEJGRgbp6em0bt2ac845h8suu4zbbruN8vJy+vTpU2en8oUXXsgjjzzCa6+9Rps2bU5Z/8tf/pKHH36YNWvWhCrsejweHnvsMe655x5s2yY9PZ2nnnqKkpKS0H4DBgzgqaeeIj8//6TqtnfffTf33HMPXbp0ISv4SEBD4mlK9Va5DSciycaYettnIjIEGGyMGSUilwKPGmN+GlzXEXgHp/hhKvBh8PXTwN+NMfNFZBJOslmIk7AuDG67BTjLGFNr0E1R5RbgP1OmcvQvf+Hs9R+e9rGUaqm0ym3zFOkqtyFuEkbQlcDbwX02ikh4IJcA640xZUCZiGwH+gT3yQtu8xaQZ4yZLSIXGGMqRaQbUFpXwmhKnswM7dNQStXp/vvvP+XZioyMDObNmxejiCIvUnOEZwHh76RfRHzGmMoa1h0FWldbXrWMYMK4H5gGPB+heE/hzczCLi8nUFaGJyUlWqdVSjUjc+bMiXUIUeeqjpSIfF9EBopIVxFxMx3UESAz/DzBhFHTukycIb3hy6uWAWCMmQN0Aq4SkWuJghPl0bW1oZRSVdw8p3E/cDPQFmfobS/g/np2Ww8MAlYE+zS+CFv3MTBTRFKBFKA3TiXd9cBAYD5wA/CBOMMXfosz7LcCp58jshPgBoWXR/edcUY0TqmUUnHPTUtjOPAjoNAY8zugn4t93gBKRWQDzhSx40VkgogMNsZ8i3Ob6QPgXeAxY0wpMAMYLiLrgcuAOcYYA3wO/BXYAGw0xqxr2CU2jidDWxpKKVWdmz4ND85w16oO6LL6djDGBIB7qy3eGrb+ZeDlavt8Bwyo4VjTcPozosqb6dwp02c1lIpfq1atCpUKqctHH33EsmXLmD17dpQiOz2FhYV88MEHDBo0KNahnMJNS2Mp8D7QS0TWAL+PbEjxwZOp5dGVUrFhjOHdd9+NdRg1ctPSmAf8GTgPMMCeiEYUJ05MxKRFC5Vy48t1f2Hze+806THPu+ZHnHv1f9W5zWeffcYvfvELiouLeeCBBygtLWXx4sVUVlZiWdYpI5wWLVrE2rVrKSkpITs7mzlz5rB69WrWrVtHaWkpe/bsYcyYMQwZMoTPP/+cvLw8AoEAHTp0YNasWezevZsZM2YA0KZNG/Ly8sjMzKwpNNauXcvLL7+Mz+ejffv2zJ49mwMHDvDrX/8agO9///v885//ZOHChdx4441069aNpKQkCgsL2bp1K8uXL2fYsGFN8E42nbrm0+gYnEPjQ5wntz/H6YxeG6XYYkonYlKqeUhLS2P+/Pnk5+czffp0du3aRX5+PkuXLqVXr158+OGJB3QDgQCFhYXMnz+fgoIC/H5/qMxHcXExL730EvPmzSM/Px+AKVOmkJeXR0FBAVdffTU7duzg8ccfZ+rUqSxcuJCrrrqKV155pdbYVq9ezV133cXSpUu59tprKS4uZu7cuQwaNIiFCxdy4YUnSvkdP36c++67j9mzZ4dKjMRbwoC6WxqXAr8CBMgPLgsAf4p0UPHA06oVWJa2NJRy6dyr/6veVkEk9O3bF8uyyMnJITMzE5/Px8SJE0lPT2fnzp2h0ufglPJISkpiwoQJtGrVim+//TZUFPCcc84BoFOnTqHChAcOHKBnz54ADB06FHAmVZo2zelmraiooFu3brXG9uijj/LSSy+xaNEievToQf/+/dm7dy/Dhw8HoF+/fqxYcaIyUlUhxXhW13wavwd+LyIDjTFrohhTXLA8HjwZGdrSUCrOVbUU9u/fz9GjR1mwYAHvvfce4JQ4Dy+VtHXrVv785z9TUFBASUkJQ4YMCa2vqTBh+/bt2bVrF926dSM/P5/u3bvTvXt3nnzySTp37symTZtCRRFrsnz5ch544AFycnKYMmUK77zzDiLCpk2bOOecc9i8efNJ23s8ntDXQCAqTxc0mJs+jUMi8hLO3OAW0NkYc31kw4oPWh5dqfhXWlrKyJEjOX78ODNnzmTZsmUMGzYMn89HVlYW+/btCxUN/N73vkdaWlroL/127dqxb9++Wo89bdo0Jk+ejMfjoV27dowaNYpOnToxceLEUJ/JzJkza92/T58+jB07lvT0dFq1asU111zDddddx6RJk/jTn/5E69ata9zvrLPOYtu2bcyfP59Ro0Y1/s2JgHoLForIp8BTwM9wHtL7vjHm51GIrVGaqmAhwM6f3kRSly6cOfd/muR4SrU0WrDw9OzYsYPc3FwWLlwY1fNGumDhAWPMUhH5sTEmV0Si8nBdPNCWhlKqPuXl5dx1112nLO/evTvTp0+PQUSR5SZpBETkXKBVsKxH2wjHFDc8mZlUfPttrMNQSsWx5OTkRrcUevbsGfVWxuly83DfBOBcnNIfS4BXIxpRHPFkZhA4oqOnlFKqSr0tDWPMlyLyL5xJkAZyopxIi+fNzMJfrKOnlFKqipsqt6/jTJBUiDN6ygYuinBccaFqIibbtmscjqeUUonGTZ+GGGN6RDySOOTNzIJAgMCx43gz0mMdjlJKxZybPo2Pgx3gCSc0EVOxjqBSKh6tWrWKWbNm1bvdRx99xPjx4yMay5NPPsmwYcO45ZZbTnrKu6Vx09IoAv4mIsUEb08ZYzpHNqz4ECqPfuQISR07xjgapVS82rhxI3v27GH58uWUl5fzk5/8hOuvv77Wh/eaMzdJ4zqgbdh0rQkjVB5dO8OVqtexTd9x7JPvmvSY6Rd3IL1vhzq3iYcqtxdeeOFJD8v5/X58Pjcfr82Pm9tT24C6f2otVKg8ug67VSpuxUOV25SUFFq3bk1FRQWTJk1i2LBhpKe3zH5QN6nwSmCXiBwIfp8wt6d0Iial3EvvW3+rIBLipcptUVER48aN45JLLmHs2LFRufZYcPOcRq9oBBKPvNoRrlTci4cqt6WlpYwaNYrRo0czePDgyF90DNWaNETkN8aYGSKylGoP9BljRkQ8sjjgCXWEa9JQKl7FQ5XbZcuW8a9//YuCggIKCgoAyMvL48wzz4z8GxBltVa5FZHzjTGfi8jV1dcZY+K2aGFTVrm1bRvT53zajvoF7YPTMyqlTtAqt81TpKrcbhaRZJzZ+4bhDLf1Av+LM6KqxbMsC09mprY0lFIqqK6kcScwGegIGJykEQA+iEJccUPLoyul1Al1Tff6MvCyiNxpjHktijHFFU9mJn7tCFdKKcDdkNtPROQynFZGHpBnjPlLZMOKH055dE0aSikF7h7uexEoA34DPAZMjWhEccYpj65JQymlwF3SKAW+BJKNMRsBf2RDii/a0lBKqRPcJA0beB1YIyK3AhWRDSm+6ERMSsWveKpyO3v2bIYOHcqtt97KRx99FNFzxZKbpDEMWGCMeQ7YDwyPbEjxxZOZgX38OHZlwtVrVEq5tGXLFj777DNWrFjBs88+y8yZM2MdUsS46QgvAy4XkZ8Bq4G2wKGIRhVHQuXRjx7Fl50d42iUil+fffYZn376aZMe88ILLzypdlRt5411ldsf/OAHvPrqq1iWxTfffENWVlaTvg/xxE1L4zVgJ/B94Fvg1YhGFGe0PLpS8S0eqtwC+Hw+Zs+ezdixYxkyZEj034gocdPSyDHGvCYitxtjNoiIm0TTYmh5dKXcueCCC+ptFURCvFS5BRg/fjxjxoxh2LBhXHzxxZx11lkRv/5oczVLiIicE/zaFaj35n4wscwFzse5vXW3MWZ72PoxwNjgsWYYY1aLyBnAEiAN+AYYbYw5LiLjOdGPssYYM83txTUFLY+uVHyLhyq3f/3rX1m7di1Tp04lJSUFn89X4/FaAjdJYxzw/wK9gf8PuM/FPjcBqcaYy0TkUuAZ4KcAItIxeMyLgVTgQxF5B5gCLDHGzBeRScBYEfkD8HOgH87DhR+KyBvGmH805CJPh5ZHVyq+xUOV27POOou3336b4cOHEwgE+PnPf94iK9yCu/k0NgOXNfC4VwJvB/ffKCLhlRMvAdYbY8qAMhHZDvQJ7pMX3Oat4Os5wABjjB9ARJJwnhuJGk+wQ8tfpLe4BPUpAAAULElEQVSnlIo3Q4YMOaX/4LLLav646tevHwCvv/56ncdMSUnh3XffBaBPnz4sWbLkpPXnnXceCxcuPGW/qltWLV2kJrHNAorCvveLiC84z3j1dUeB1tWWHwVaG2MqgAMiYgFPA58aY7ZFKOYaedu0AcBfVFTPlkop1fJFqlP7CJAZfp5gwqhpXSZQWG151TJEJBVYHFzm5tZYk/Kkp0NSEv7Dh6N9aqWUijv1Jg0RWVLfNjVYDwwM7n8p8EXYuo+BH4pIqoi0xukr2Ry+D3AD8EGwhfEH4HNjzNiq21TRZFkWvjZtqDycMI+mKNUgtU3kpuLT6f683NyeShGRPsA2nM5ojDHl9ezzBvAjEdmAMw/HaBGZAGw3xvxRRJ7HmZfDAzxmjCkVkRnAguDIqgPACJwO9auDMdwQPPajxpi/NuwyT4+3bVv8hwujeUqlmoXU1FQOHjxITk5Oix0t1JLYts3BgwdJTU1t9DHcJI2zcf7aD50X6FHXDsaYAHBvtcVbw9a/DLxcbZ/vgAHV9nkDZ4RVTHmzs/X2lFI16Nq1K3v37mX//v2xDkW5lJqaGhpN1hhuRk/9PwAikgMcMsYkXFvUm92Gsq+21r+hUgkmKSmJ7t27xzoMFUVu+jSuEpHNwIfANBG5K/JhxReftjSUUgpwN3pqBnAVTt2pPGIwginWvNlt8R85opVulVIJz03SCBhjDgG2MaYU5xmKhOLNzgbb1vpTSqmE5yZpbBeR3wI5wfIeuyMcU9zxZgcf8Dukw26VUonNTdK4FydRfAgcA+6OaERxyNe2LYD2ayilEp6bIbe/M8bcX/WNiLwOjIxcSPHHG5x8qVKThlIqwdWaNETkv4HfAG1FpKoimAVsiUZg8aQqafgPadJQSiW2WpOGMeZ/gP8RkcnGmLzatksEoaRRqElDKZXY3NyemiMi/xfogjNH+D/CJ1RKBJ7kZDzp6dqnoZRKeG46wl8FviZB5wiv4s3O1j4NpVTCc5M0cowxrwEVxpgNLvdpcbzZ2dqnoZRKeK4SQEPnCG+JvNlt9PaUUirhuUkaVXOEX4QzR/ivIxpRnPJlt9WkoZRKeJGaI7zF0T4NpZRykTREZCZwJ848GgAYYzpHMqh45M3Oxi4pIVBSgictLdbhKKVUTLgZcvsToJsxpizSwcQzb9uqZzUKNWkopRKWmz6NT4mD2fNizVf1gJ/eolJKJTA3LY3NwH9E5FucMiK2MabO6V5bolD9KR12q5RKYG6SxjCgO1AY4VjimldbGkop5Spp7AaOJXyfhiYNpZRylTTOBHaIyM7g97Yx5vIIxhSXvFlZ4PFQeVgnYlJKJS63t6cSnuX14m3dWlsaSqmE5iZpJAFDg18toDMwNpJBxStv27b4Dyd0145SKsG5GXK7JPj1SpwO8ZzIhRPftP6UUirRuUkaxcaY3wJ7jTGjgA6RDSl++bKz8WufhlIqgblJGraIdAQyRSQdyIhwTHHL2yabSr09pZRKYG6SxjTgJmAhsBP4S0QjimNOn8ZhbNuuf2OllGqB3HSEX2KMmRV8/cdIBhPvvNltwO8ncOQI3tatYx2OUkpFnZuWxkAR8UY8kmZA608ppRKdm5ZGO+AbEfkapzx6Qj7cB87tKYDKw4dJ7tYttsEopVQMuEkaN0Y8imbC26aqpaGd4UqpxBSRh/tExAPMBc4HyoC7jTHbw9aPCR6jEphhjFktImfgPBOSBnwDjDbGHA9u3w5YD/QxxpQ26Aqb0In6UzrsVimVmCL1cN9NQKox5jJgEvBM1Yrg8N1xwBXA9cBvRSQFmAIsMcb8EGcOj7HB7a8H1gId3VxQJPmy2wDap6GUSlyRerjvSuBtAGPMRuDisHWXAOuNMWXGmCJgO9AnfB/gLaB/8HUg+Drmf95brVphpaToXOFKqYQVqYf7soCisO/9IuKrZd1RoHW15VXLMMa8Y4w56OKcEWdZFt7sbPw6EZNSKkG5fbjvZhr2cN8RIDP8PMaYylrWZeJM8BS+vGpZ3PFmZ+vtKaVUwqqzI1xEsoBPjDHvBxe5fbhvPTAIWCEilwJfhK37GJgpIqlACtAbZ0rZ9cBAYD5wA/CBy3NFlU+ThlIqgdXa0hCR+4HPgc+DndEN8QZQKiIbgNnAeBGZICKDjTHfAs/jJIV3gceCI6JmAMNFZD1wGTCn4ZcTed7sbCoLNWkopRJTXS2NEYDg9DUsBP7k9qDGmABwb7XFW8PWvwy8XG2f74ABdRyzm9vzR5L2aSilElldfRqlxphyY8wBIDlaAcU7b3YbAkePYldUxDoUpZSKOjcd4eA81KcAX7CUiL8wLvvplVIqouq6PXWuiCzBSRhVrwEwxoyIeGRxquqp8MrDh/G1axfjaJRSKrrqShq3hr1+MdKBNBeh+lPar6GUSkC1Jg1jzLpoBtJchOpP6QgqpVQCctunoYJ8bXVODaVU4tKk0UDeNk7RwspDMS+FpZRSUadJo4GspCQ8mZk6p4ZSKiFp0mgEb1stJaKUSkyaNBrB10aThlIqMWnSaARvdrbOqaGUSkiaNBpBy6MrpRKVJo1GqOrTsG071qEopVRUadJoBF92NnZZGfbx47EORSmlokqTRiOcqD+lw26VUolFk0YjeLODlW61X0MplWA0aTSCN9t5KlzrTymlEo0mjUbwVRUt1FIiSqkEo0mjEcLn1FBKqUSiSaMRPFlZ4PVq/SmlVMLRpNEIlmU5D/jp7SmlVILRpNFIvuw22hGulEo4mjQayZvdVvs0lFIJR5NGIzn1p7RPQymVWDRpNJI3u432aSilEo4mjUbyZmfjLyrC9vtjHYpSSkWNJo1G8mW3hUAA/5EjsQ5FKaWiRpNGI1U94Kf1p5RSiUSTRiNp0lBKJSJNGo0UKlqoSUMplUA0aTSSr61THl2f1VBKJRJNGo3kbRNsaRzSpKGUShy+SBxURDzAXOB8oAy42xizPWz9GGAsUAnMMMasFpEzgCVAGvANMNoYc7ymbSMRc0N50tKw0tL09pRSKqFEJGkANwGpxpjLRORS4BngpwAi0hEYB1wMpAIfisg7wBRgiTFmvohMAsaKyNKatjXGlEUi6IrScmzbBo8FlosdcnIoPXCAMh12G3csy80PUNWnMe+j233cbKc/xwbwevEkJ0f8NJFKGlcCbwMYYzaKyMVh6y4B1gc/+MtEZDvQJ7hPXnCbt4Kvd9Sy7d+aOuCXH8vjG185dkN+R6+8wvn67LNNHY5SqiFsOwrnqPWb6Kvh9JYdoPXxYh589ncRPXWkkkYWUBT2vV9EfMaYyhrWHQVaV1te07Lw5U2uxD5Cl+IssCwsLAj/r2XhwcLCg8dyXlmWBw8evHjxerx4LR9ey4tVRzdRwPbjt/34qSQQCL62/fjtSgL4qbT9BOxKKm0//kBlaJ0/uDzGv6Yq0TTqj/ymaxk06A+4ep3mwaLe4HF5wvDNbJtAq8h3U0cqaRwBMsO+9wQTRk3rMoHCsOUlNSyrvm2TG5f3xGkfw7Zt7DI/geOVBEoqCZRUhL2udF4fr3C2KakkUFqJXeonUOq8prKOtGCBleLD08qHJ+3Uf1b1Za2STqxL8WJ5tJmvlDp9kUoa64FBwIpgn8YXYes+BmaKSCqQAvQGNgf3GQjMB24APqhj27hkWRZWqg9PauPeVrvCfyLBVCWZsO/tkpO/ryg6FnqNv+6EU2NiSfPhSUs6KRGFtgkus5K9el9ZKRUSqaTxBvAjEdmA04AaLSITgO3GmD+KyPM4ScEDPGaMKRWRGcCC4GipA8AIY8yxmraNUMwxZyV58SZ58WalNGg/27axKwInkspJyabilCRkl1RScbgstI5AHQf3WHjSvHjSkmpOOq1OTUBV21lJHk04SrUwlh2NDqQoGjJkiL1q1apYh9Fs2LaNXe4/JamcnGgqam3x1NnR4rVqSDJJtdxOq3a7LckbtfdAKQUisskYc3F920WqpaGaCcuynL6SFB+0adi+diCYcI5Xa9XUlHxKKvEXV1Cxv4TA8Urs0sq6D+7z1JlUPGk+rLB+m5OW+/SZVaUiRZOGajTL0/g+HDtgY5fW3n8TPojALqnEX1hGxX+cPhy7rO45TKwkz4k+marbZjUkoFNvtyVhefV2mooPtm2D3yZQ5scud/4FyvzYZWGvy53vA2V+sCHjis54MyL7rIYmDRUTlsdyWgqtkhq8r+0P1D5AoIbk4z9UQkXVtuV1deCAleKteWRaqxqST3gCSvXpCLUWyq4M4D9ajv9oOYEj5fiLK0If4nZlwOlPDP7Dcv5osXyek77isU5sV+4PfQ2UB7Ar/NjlJ5YHqo5dHoCAy+6D4GCXtHNzNGkoVZ3l9eDNSG7U/xx2ZaBaUqlKNhWn3E4LlFQ6t9Oq+m8q60k4qd5ThjvXOmpNh0SfttAQ92NOq9Qf/BnafucvdDsQwK60IWAHlwWw/Ta2PwCVzlfbb0NlcHllIPjP2TZQ5idwtJzA8TpupXqtEwkiyQM2JxJJZeDUUY0eZ8CLlexxRib6PHiSne89rVKcZUlVy7zOHzHJHud3JLjME1xupXjxBL9aPk/Ufoc0aaiEYvk8eDOT8WY2IuFUBE7cOovmkOjabqm1al5DokN9YCWVBEr9zvtVWsd7WOq8b1W3abBt7AAQcG7ZBI5X1P2+1sRjObcgvR4sn+V80PqCr71OywCfhZXixZeRjLd769DviycrOfQ69EFdz+1MO+AkIwK2k1i8zb+/TZOGUi5ZSR68Scl4sxqWcKqGRIc+FI9XVGvlnPrB6QyJdhKU2yHRJ99Kqz35uBkSbQeCw7irbp2EfQ1U3Uqpup9e7scuC4Tdc690vpb6CZQ5fVCBUmf7+soaVL89SJIHj8cK1oOzsDzBa6560DXducXpSQ++TvWdSAreqgRhYXk8wa/RTbCWx8JKblkjATVpKBVhlmWFbivQuhHP4NQ1JLp6EjpeQeXBktA2roZEp/pO3Jqp7bZKfTxgJfvwpHic0XipXqxUL0ltUk7cRgkOmnDW+ZxkF1xmBePQgQjxT5OGUnHstIdEl4VXGahlSHSZ3/mLOOnEvfnQffrgPfbqX0P31ZOdhIDXaja3ydTp0aShVAtleazQrSilmkrz75VRSikVNZo0lFJKuaZJQymllGuaNJRSSrmmSUMppZRrmjSUUkq5pklDKaWUa5o0lFJKudbinvr58ssvD4jI7ljHoZRSzcz33GzU4qZ7VUopFTl6e0oppZRrmjSUUkq5pklDKaWUa5o0lFJKuaZJQymllGstbshtFRHxAHOB84Ey4G5jzPaw9WOAsUAlMMMYszomgUZIfdcf3KYdsB7oY4wpjX6UkeHiZz8eGB78do0xZlr0o4wcF9f/38AonHn9ZhljVsQizkhw+XvvAf4X+IMx5sXoRxkZLn7uzwFXAkeDi35qjClq6HlackvjJiDVGHMZMAl4pmqFiHQExgFXANcDvxWRhs3DGf9qvX4AEbkeWAt0jEFskVbXz74H8HPgcuBS4Mci0icmUUZOXdd/BvBLnOv/L+AZEWlJU+7V+XsfNAPIjmpU0VHftfcFrjfGXBP81+CEAS07aVwJvA1gjNkIXBy27hJgvTGmLPjGbQda2gdHXdcPEAD6A4eiHFc01HXt/wIGGGP8xhgbSAJaTCsrqNbrN8YcAC4wxlTg/MFQGnwfWoo6f+9F5Gc4v/tvRz+0iKv12oOtkO8D+SKyXkTubOxJWnLSyALCM6lfRHy1rDsKtI5WYFFS1/VjjHnHGHMw+mFFRa3XboypMMYcEBFLRGYBnxpjtsUkysip72dfKSL3AxuBRdEOLsJqvXYROQ8YAUyJRWBRUNfPPR14AbgdGADc19gWdktOGkeAzLDvPcaYylrWZQKF0QosSuq6/pauzmsXkVRgcXCb+6IcWzTU+7M3xswBOgFXici10Qwuwuq69pFAF+BdnD6dCSIyILrhRVRd134ceM4Yc9wYcxTnPTi/MSdpsR3hOB28g4AVInIp8EXYuo+BmcEPjxSgN7A5+iFGVF3X39LVeu3B+/d/AN41xjwZo/gira7rF+C3wC1ABU6HaSAWQUZIrddujHmk6rWI5ALfGmNa0m2quv6fPxtYLiIX4jQWrgQWNOYkLbb2VNhIgj6ABYwGBgLbjTF/DI6eugfnDcwzxqyMWbARUN/1h223CzinhY6eOuXaAS+wFOfWTJVHjTF/jXackeLid38qcAPO6Km3jDHTYxZsE2vA730uTtJoiaOnavu5PwzcivPHwuuNvfYWmzSUUko1vZbcp6GUUqqJadJQSinlmiYNpZRSrmnSUEop5ZomDaWUUq5p0lCqAURklIg80ch9u4nIxnq2GSAi8xsVnFJRoElDKaWUay35iXClIkZEfotTEC4H+NwYMzr4wFgv4Izg8v/BefL6bOAXwLdAOxH5I9ABWG2M+b8i0ht4DTgW/Hc4eI77gSE4dYMOADcbY8qjdpFK1UBbGko1XDJw2BjzI5zEcamIdAmuKzHGDABWAgONMYOAJzgxf0cGcAdOafIbROR84GlgijGmP7ABQk/35gD9jTH9cP7A+z9RuTql6qAtDaUazgbai8hSoBgnESQF1/09+LUQ2BJ8fRhIDb7+vGoeAxH5GKcVcjZOPTRw6gf1NsYERKQcWCoixUDXsHMoFTPa0lCq4a4FzjTG3AZMBtJwav2Ak1Dq0ltEMoIlq/sBX+Ikl8uC6/8PQLBs9U3GmGHAAzj/r7akyZJUM6UtDaUa7mOgr4i8j5MkdgKdXe57CFgOtAOWG2O2iMivgQXBgnL7cSaF2g4cE5H1wf3+04BzKBUxWrBQKaWUa3p7SimllGuaNJRSSrmmSUMppZRrmjSUUkq5pklDKaWUa5o0lFJKuaZJQymllGuaNJRSSrn2/wONd7wud5wwTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = []\n",
    "for col in lasso_alpha.drop(columns=['alpha', 'student']):\n",
    "    plt.plot(lasso_alpha['alpha'], lasso_alpha[col])\n",
    "    labels.append(col)\n",
    "    \n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('Parameter estimate size')\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge(alphas, x, y):\n",
    "    '''Alphas are list of alphas, x is training \n",
    "    data and y is training target'''\n",
    "    \n",
    "    special_lst = []\n",
    "    for alpha in alphas:\n",
    "        ridgid = linear_model.Ridge(alpha=alpha, fit_intercept=False)\n",
    "        ridgid.fit(x, y)\n",
    "        special_lst.append(pd.DataFrame(ridgid.coef_))\n",
    "        \n",
    "    special_df = pd.DataFrame(special_lst)\n",
    "    \n",
    "    special_df.columns = x.columns\n",
    "    special_df['alpha'] = alphas\n",
    "    \n",
    "    return special_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number1.822550e-18\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number3.646343e-18\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number5.471431e-18\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.297796e-18\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number9.125420e-18\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number1.095429e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number1.278438e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number1.461568e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number1.644818e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number1.828186e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number2.011670e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number2.195268e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number2.378980e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number2.562803e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number2.746737e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number2.930780e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number3.114931e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number3.299187e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number3.483548e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number3.668013e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number3.852580e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number4.037248e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number4.222016e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number4.406882e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number4.591845e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number4.776904e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number4.962058e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number5.147306e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number5.332646e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number5.518078e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number5.703599e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number5.889210e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number6.074910e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number6.260696e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number6.446568e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number6.632526e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number6.818567e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.004692e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.190898e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.377186e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.563554e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.750001e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number7.936526e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.123129e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.309808e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.496564e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.683393e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number8.870297e-17\n",
      "  overwrite_a=True).T\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:112: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number9.057274e-17\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>balance_student</th>\n",
       "      <th>balance_default</th>\n",
       "      <th>student_default</th>\n",
       "      <th>balance_sqrt</th>\n",
       "      <th>balance2</th>\n",
       "      <th>balance3</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005529</td>\n",
       "      <td>-0.005529</td>\n",
       "      <td>-0.005529</td>\n",
       "      <td>-0.005529</td>\n",
       "      <td>-0.005529</td>\n",
       "      <td>-0.005529</td>\n",
       "      <td>-0.005529</td>\n",
       "      <td>-0.005529</td>\n",
       "      <td>-0.005529</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005511</td>\n",
       "      <td>-0.005511</td>\n",
       "      <td>-0.005511</td>\n",
       "      <td>-0.005511</td>\n",
       "      <td>-0.005511</td>\n",
       "      <td>-0.005511</td>\n",
       "      <td>-0.005511</td>\n",
       "      <td>-0.005511</td>\n",
       "      <td>-0.005511</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005492</td>\n",
       "      <td>-0.005492</td>\n",
       "      <td>-0.005492</td>\n",
       "      <td>-0.005492</td>\n",
       "      <td>-0.005492</td>\n",
       "      <td>-0.005492</td>\n",
       "      <td>-0.005492</td>\n",
       "      <td>-0.005492</td>\n",
       "      <td>-0.005492</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.005474</td>\n",
       "      <td>-0.005474</td>\n",
       "      <td>-0.005474</td>\n",
       "      <td>-0.005474</td>\n",
       "      <td>-0.005474</td>\n",
       "      <td>-0.005474</td>\n",
       "      <td>-0.005474</td>\n",
       "      <td>-0.005474</td>\n",
       "      <td>-0.005474</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.005456</td>\n",
       "      <td>-0.005456</td>\n",
       "      <td>-0.005456</td>\n",
       "      <td>-0.005456</td>\n",
       "      <td>-0.005456</td>\n",
       "      <td>-0.005456</td>\n",
       "      <td>-0.005456</td>\n",
       "      <td>-0.005456</td>\n",
       "      <td>-0.005456</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.005438</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.005420</td>\n",
       "      <td>-0.005420</td>\n",
       "      <td>-0.005420</td>\n",
       "      <td>-0.005420</td>\n",
       "      <td>-0.005420</td>\n",
       "      <td>-0.005420</td>\n",
       "      <td>-0.005420</td>\n",
       "      <td>-0.005420</td>\n",
       "      <td>-0.005420</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.005403</td>\n",
       "      <td>-0.005403</td>\n",
       "      <td>-0.005403</td>\n",
       "      <td>-0.005403</td>\n",
       "      <td>-0.005403</td>\n",
       "      <td>-0.005403</td>\n",
       "      <td>-0.005403</td>\n",
       "      <td>-0.005403</td>\n",
       "      <td>-0.005403</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.005385</td>\n",
       "      <td>-0.005385</td>\n",
       "      <td>-0.005385</td>\n",
       "      <td>-0.005385</td>\n",
       "      <td>-0.005385</td>\n",
       "      <td>-0.005385</td>\n",
       "      <td>-0.005385</td>\n",
       "      <td>-0.005385</td>\n",
       "      <td>-0.005385</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.005368</td>\n",
       "      <td>-0.005368</td>\n",
       "      <td>-0.005368</td>\n",
       "      <td>-0.005368</td>\n",
       "      <td>-0.005368</td>\n",
       "      <td>-0.005368</td>\n",
       "      <td>-0.005368</td>\n",
       "      <td>-0.005368</td>\n",
       "      <td>-0.005368</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.005334</td>\n",
       "      <td>-0.005334</td>\n",
       "      <td>-0.005334</td>\n",
       "      <td>-0.005334</td>\n",
       "      <td>-0.005334</td>\n",
       "      <td>-0.005334</td>\n",
       "      <td>-0.005334</td>\n",
       "      <td>-0.005334</td>\n",
       "      <td>-0.005334</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.005317</td>\n",
       "      <td>-0.005317</td>\n",
       "      <td>-0.005317</td>\n",
       "      <td>-0.005317</td>\n",
       "      <td>-0.005317</td>\n",
       "      <td>-0.005317</td>\n",
       "      <td>-0.005317</td>\n",
       "      <td>-0.005317</td>\n",
       "      <td>-0.005317</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.005301</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.005284</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.005268</td>\n",
       "      <td>-0.005268</td>\n",
       "      <td>-0.005268</td>\n",
       "      <td>-0.005268</td>\n",
       "      <td>-0.005268</td>\n",
       "      <td>-0.005268</td>\n",
       "      <td>-0.005268</td>\n",
       "      <td>-0.005268</td>\n",
       "      <td>-0.005268</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.005252</td>\n",
       "      <td>-0.005252</td>\n",
       "      <td>-0.005252</td>\n",
       "      <td>-0.005252</td>\n",
       "      <td>-0.005252</td>\n",
       "      <td>-0.005252</td>\n",
       "      <td>-0.005252</td>\n",
       "      <td>-0.005252</td>\n",
       "      <td>-0.005252</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.005236</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.005220</td>\n",
       "      <td>-0.005220</td>\n",
       "      <td>-0.005220</td>\n",
       "      <td>-0.005220</td>\n",
       "      <td>-0.005220</td>\n",
       "      <td>-0.005220</td>\n",
       "      <td>-0.005220</td>\n",
       "      <td>-0.005220</td>\n",
       "      <td>-0.005220</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.005204</td>\n",
       "      <td>-0.005204</td>\n",
       "      <td>-0.005204</td>\n",
       "      <td>-0.005204</td>\n",
       "      <td>-0.005204</td>\n",
       "      <td>-0.005204</td>\n",
       "      <td>-0.005204</td>\n",
       "      <td>-0.005204</td>\n",
       "      <td>-0.005204</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.005188</td>\n",
       "      <td>-0.005188</td>\n",
       "      <td>-0.005188</td>\n",
       "      <td>-0.005188</td>\n",
       "      <td>-0.005188</td>\n",
       "      <td>-0.005188</td>\n",
       "      <td>-0.005188</td>\n",
       "      <td>-0.005188</td>\n",
       "      <td>-0.005188</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.005173</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.005158</td>\n",
       "      <td>-0.005158</td>\n",
       "      <td>-0.005158</td>\n",
       "      <td>-0.005158</td>\n",
       "      <td>-0.005158</td>\n",
       "      <td>-0.005158</td>\n",
       "      <td>-0.005158</td>\n",
       "      <td>-0.005158</td>\n",
       "      <td>-0.005158</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.005142</td>\n",
       "      <td>-0.005142</td>\n",
       "      <td>-0.005142</td>\n",
       "      <td>-0.005142</td>\n",
       "      <td>-0.005142</td>\n",
       "      <td>-0.005142</td>\n",
       "      <td>-0.005142</td>\n",
       "      <td>-0.005142</td>\n",
       "      <td>-0.005142</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.005127</td>\n",
       "      <td>-0.005127</td>\n",
       "      <td>-0.005127</td>\n",
       "      <td>-0.005127</td>\n",
       "      <td>-0.005127</td>\n",
       "      <td>-0.005127</td>\n",
       "      <td>-0.005127</td>\n",
       "      <td>-0.005127</td>\n",
       "      <td>-0.005127</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.005112</td>\n",
       "      <td>-0.005112</td>\n",
       "      <td>-0.005112</td>\n",
       "      <td>-0.005112</td>\n",
       "      <td>-0.005112</td>\n",
       "      <td>-0.005112</td>\n",
       "      <td>-0.005112</td>\n",
       "      <td>-0.005112</td>\n",
       "      <td>-0.005112</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.005098</td>\n",
       "      <td>-0.005098</td>\n",
       "      <td>-0.005098</td>\n",
       "      <td>-0.005098</td>\n",
       "      <td>-0.005098</td>\n",
       "      <td>-0.005098</td>\n",
       "      <td>-0.005098</td>\n",
       "      <td>-0.005098</td>\n",
       "      <td>-0.005098</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.005083</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.005068</td>\n",
       "      <td>-0.005068</td>\n",
       "      <td>-0.005068</td>\n",
       "      <td>-0.005068</td>\n",
       "      <td>-0.005068</td>\n",
       "      <td>-0.005068</td>\n",
       "      <td>-0.005068</td>\n",
       "      <td>-0.005068</td>\n",
       "      <td>-0.005068</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.005054</td>\n",
       "      <td>-0.005054</td>\n",
       "      <td>-0.005054</td>\n",
       "      <td>-0.005054</td>\n",
       "      <td>-0.005054</td>\n",
       "      <td>-0.005054</td>\n",
       "      <td>-0.005054</td>\n",
       "      <td>-0.005054</td>\n",
       "      <td>-0.005054</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.005025</td>\n",
       "      <td>-0.005025</td>\n",
       "      <td>-0.005025</td>\n",
       "      <td>-0.005025</td>\n",
       "      <td>-0.005025</td>\n",
       "      <td>-0.005025</td>\n",
       "      <td>-0.005025</td>\n",
       "      <td>-0.005025</td>\n",
       "      <td>-0.005025</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.004997</td>\n",
       "      <td>-0.004997</td>\n",
       "      <td>-0.004997</td>\n",
       "      <td>-0.004997</td>\n",
       "      <td>-0.004997</td>\n",
       "      <td>-0.004997</td>\n",
       "      <td>-0.004997</td>\n",
       "      <td>-0.004997</td>\n",
       "      <td>-0.004997</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.004970</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.004956</td>\n",
       "      <td>-0.004956</td>\n",
       "      <td>-0.004956</td>\n",
       "      <td>-0.004956</td>\n",
       "      <td>-0.004956</td>\n",
       "      <td>-0.004956</td>\n",
       "      <td>-0.004956</td>\n",
       "      <td>-0.004956</td>\n",
       "      <td>-0.004956</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-0.004943</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.004929</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.004916</td>\n",
       "      <td>-0.004916</td>\n",
       "      <td>-0.004916</td>\n",
       "      <td>-0.004916</td>\n",
       "      <td>-0.004916</td>\n",
       "      <td>-0.004916</td>\n",
       "      <td>-0.004916</td>\n",
       "      <td>-0.004916</td>\n",
       "      <td>-0.004916</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.004903</td>\n",
       "      <td>-0.004903</td>\n",
       "      <td>-0.004903</td>\n",
       "      <td>-0.004903</td>\n",
       "      <td>-0.004903</td>\n",
       "      <td>-0.004903</td>\n",
       "      <td>-0.004903</td>\n",
       "      <td>-0.004903</td>\n",
       "      <td>-0.004903</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.004890</td>\n",
       "      <td>-0.004890</td>\n",
       "      <td>-0.004890</td>\n",
       "      <td>-0.004890</td>\n",
       "      <td>-0.004890</td>\n",
       "      <td>-0.004890</td>\n",
       "      <td>-0.004890</td>\n",
       "      <td>-0.004890</td>\n",
       "      <td>-0.004890</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.004877</td>\n",
       "      <td>-0.004877</td>\n",
       "      <td>-0.004877</td>\n",
       "      <td>-0.004877</td>\n",
       "      <td>-0.004877</td>\n",
       "      <td>-0.004877</td>\n",
       "      <td>-0.004877</td>\n",
       "      <td>-0.004877</td>\n",
       "      <td>-0.004877</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.004864</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.004851</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>-0.004839</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.004826</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.004801</td>\n",
       "      <td>-0.004801</td>\n",
       "      <td>-0.004801</td>\n",
       "      <td>-0.004801</td>\n",
       "      <td>-0.004801</td>\n",
       "      <td>-0.004801</td>\n",
       "      <td>-0.004801</td>\n",
       "      <td>-0.004801</td>\n",
       "      <td>-0.004801</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     default   student   balance  balance_student  balance_default  \\\n",
       "0  -0.005529 -0.005529 -0.005529        -0.005529        -0.005529   \n",
       "1  -0.005511 -0.005511 -0.005511        -0.005511        -0.005511   \n",
       "2  -0.005492 -0.005492 -0.005492        -0.005492        -0.005492   \n",
       "3  -0.005474 -0.005474 -0.005474        -0.005474        -0.005474   \n",
       "4  -0.005456 -0.005456 -0.005456        -0.005456        -0.005456   \n",
       "5  -0.005438 -0.005438 -0.005438        -0.005438        -0.005438   \n",
       "6  -0.005420 -0.005420 -0.005420        -0.005420        -0.005420   \n",
       "7  -0.005403 -0.005403 -0.005403        -0.005403        -0.005403   \n",
       "8  -0.005385 -0.005385 -0.005385        -0.005385        -0.005385   \n",
       "9  -0.005368 -0.005368 -0.005368        -0.005368        -0.005368   \n",
       "10 -0.005351 -0.005351 -0.005351        -0.005351        -0.005351   \n",
       "11 -0.005334 -0.005334 -0.005334        -0.005334        -0.005334   \n",
       "12 -0.005317 -0.005317 -0.005317        -0.005317        -0.005317   \n",
       "13 -0.005301 -0.005301 -0.005301        -0.005301        -0.005301   \n",
       "14 -0.005284 -0.005284 -0.005284        -0.005284        -0.005284   \n",
       "15 -0.005268 -0.005268 -0.005268        -0.005268        -0.005268   \n",
       "16 -0.005252 -0.005252 -0.005252        -0.005252        -0.005252   \n",
       "17 -0.005236 -0.005236 -0.005236        -0.005236        -0.005236   \n",
       "18 -0.005220 -0.005220 -0.005220        -0.005220        -0.005220   \n",
       "19 -0.005204 -0.005204 -0.005204        -0.005204        -0.005204   \n",
       "20 -0.005188 -0.005188 -0.005188        -0.005188        -0.005188   \n",
       "21 -0.005173 -0.005173 -0.005173        -0.005173        -0.005173   \n",
       "22 -0.005158 -0.005158 -0.005158        -0.005158        -0.005158   \n",
       "23 -0.005142 -0.005142 -0.005142        -0.005142        -0.005142   \n",
       "24 -0.005127 -0.005127 -0.005127        -0.005127        -0.005127   \n",
       "25 -0.005112 -0.005112 -0.005112        -0.005112        -0.005112   \n",
       "26 -0.005098 -0.005098 -0.005098        -0.005098        -0.005098   \n",
       "27 -0.005083 -0.005083 -0.005083        -0.005083        -0.005083   \n",
       "28 -0.005068 -0.005068 -0.005068        -0.005068        -0.005068   \n",
       "29 -0.005054 -0.005054 -0.005054        -0.005054        -0.005054   \n",
       "30 -0.005040 -0.005040 -0.005040        -0.005040        -0.005040   \n",
       "31 -0.005025 -0.005025 -0.005025        -0.005025        -0.005025   \n",
       "32 -0.005011 -0.005011 -0.005011        -0.005011        -0.005011   \n",
       "33 -0.004997 -0.004997 -0.004997        -0.004997        -0.004997   \n",
       "34 -0.004984 -0.004984 -0.004984        -0.004984        -0.004984   \n",
       "35 -0.004970 -0.004970 -0.004970        -0.004970        -0.004970   \n",
       "36 -0.004956 -0.004956 -0.004956        -0.004956        -0.004956   \n",
       "37 -0.004943 -0.004943 -0.004943        -0.004943        -0.004943   \n",
       "38 -0.004929 -0.004929 -0.004929        -0.004929        -0.004929   \n",
       "39 -0.004916 -0.004916 -0.004916        -0.004916        -0.004916   \n",
       "40 -0.004903 -0.004903 -0.004903        -0.004903        -0.004903   \n",
       "41 -0.004890 -0.004890 -0.004890        -0.004890        -0.004890   \n",
       "42 -0.004877 -0.004877 -0.004877        -0.004877        -0.004877   \n",
       "43 -0.004864 -0.004864 -0.004864        -0.004864        -0.004864   \n",
       "44 -0.004851 -0.004851 -0.004851        -0.004851        -0.004851   \n",
       "45 -0.004839 -0.004839 -0.004839        -0.004839        -0.004839   \n",
       "46 -0.004826 -0.004826 -0.004826        -0.004826        -0.004826   \n",
       "47 -0.004814 -0.004814 -0.004814        -0.004814        -0.004814   \n",
       "48 -0.004801 -0.004801 -0.004801        -0.004801        -0.004801   \n",
       "\n",
       "    student_default  balance_sqrt  balance2  balance3  alpha  \n",
       "0         -0.005529     -0.005529 -0.005529 -0.005529   0.01  \n",
       "1         -0.005511     -0.005511 -0.005511 -0.005511   0.02  \n",
       "2         -0.005492     -0.005492 -0.005492 -0.005492   0.03  \n",
       "3         -0.005474     -0.005474 -0.005474 -0.005474   0.04  \n",
       "4         -0.005456     -0.005456 -0.005456 -0.005456   0.05  \n",
       "5         -0.005438     -0.005438 -0.005438 -0.005438   0.06  \n",
       "6         -0.005420     -0.005420 -0.005420 -0.005420   0.07  \n",
       "7         -0.005403     -0.005403 -0.005403 -0.005403   0.08  \n",
       "8         -0.005385     -0.005385 -0.005385 -0.005385   0.09  \n",
       "9         -0.005368     -0.005368 -0.005368 -0.005368   0.10  \n",
       "10        -0.005351     -0.005351 -0.005351 -0.005351   0.11  \n",
       "11        -0.005334     -0.005334 -0.005334 -0.005334   0.12  \n",
       "12        -0.005317     -0.005317 -0.005317 -0.005317   0.13  \n",
       "13        -0.005301     -0.005301 -0.005301 -0.005301   0.14  \n",
       "14        -0.005284     -0.005284 -0.005284 -0.005284   0.15  \n",
       "15        -0.005268     -0.005268 -0.005268 -0.005268   0.16  \n",
       "16        -0.005252     -0.005252 -0.005252 -0.005252   0.17  \n",
       "17        -0.005236     -0.005236 -0.005236 -0.005236   0.18  \n",
       "18        -0.005220     -0.005220 -0.005220 -0.005220   0.19  \n",
       "19        -0.005204     -0.005204 -0.005204 -0.005204   0.20  \n",
       "20        -0.005188     -0.005188 -0.005188 -0.005188   0.21  \n",
       "21        -0.005173     -0.005173 -0.005173 -0.005173   0.22  \n",
       "22        -0.005158     -0.005158 -0.005158 -0.005158   0.23  \n",
       "23        -0.005142     -0.005142 -0.005142 -0.005142   0.24  \n",
       "24        -0.005127     -0.005127 -0.005127 -0.005127   0.25  \n",
       "25        -0.005112     -0.005112 -0.005112 -0.005112   0.26  \n",
       "26        -0.005098     -0.005098 -0.005098 -0.005098   0.27  \n",
       "27        -0.005083     -0.005083 -0.005083 -0.005083   0.28  \n",
       "28        -0.005068     -0.005068 -0.005068 -0.005068   0.29  \n",
       "29        -0.005054     -0.005054 -0.005054 -0.005054   0.30  \n",
       "30        -0.005040     -0.005040 -0.005040 -0.005040   0.31  \n",
       "31        -0.005025     -0.005025 -0.005025 -0.005025   0.32  \n",
       "32        -0.005011     -0.005011 -0.005011 -0.005011   0.33  \n",
       "33        -0.004997     -0.004997 -0.004997 -0.004997   0.34  \n",
       "34        -0.004984     -0.004984 -0.004984 -0.004984   0.35  \n",
       "35        -0.004970     -0.004970 -0.004970 -0.004970   0.36  \n",
       "36        -0.004956     -0.004956 -0.004956 -0.004956   0.37  \n",
       "37        -0.004943     -0.004943 -0.004943 -0.004943   0.38  \n",
       "38        -0.004929     -0.004929 -0.004929 -0.004929   0.39  \n",
       "39        -0.004916     -0.004916 -0.004916 -0.004916   0.40  \n",
       "40        -0.004903     -0.004903 -0.004903 -0.004903   0.41  \n",
       "41        -0.004890     -0.004890 -0.004890 -0.004890   0.42  \n",
       "42        -0.004877     -0.004877 -0.004877 -0.004877   0.43  \n",
       "43        -0.004864     -0.004864 -0.004864 -0.004864   0.44  \n",
       "44        -0.004851     -0.004851 -0.004851 -0.004851   0.45  \n",
       "45        -0.004839     -0.004839 -0.004839 -0.004839   0.46  \n",
       "46        -0.004826     -0.004826 -0.004826 -0.004826   0.47  \n",
       "47        -0.004814     -0.004814 -0.004814 -0.004814   0.48  \n",
       "48        -0.004801     -0.004801 -0.004801 -0.004801   0.49  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge(alphanator, X_train2, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so I try to do the exact same thing that worked with lasso and it fails with ridge.\n",
    "\n",
    "I don't know why it's complaining so much. it just did this.\n",
    "\n",
    "I still need to make it somehow return the dataframe and then I can graph the two dataframes for comparison."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
